Category	SR #	Fault Scenario	Injection Capability/Tool	PIC	Injection Tool ETA	Description	Milestone	Internal test	External test	Tested By	Test Case ETA	Test Case Reference	FPGA	Recovery	HMC Behavior	Note for Recovery	Health"Rollup" URI	OriginOfCondition	LogEntry	Severity	Message (arguments substituted by MessageArgs)	MessageId	[Reference]	MessageArgs	AdditionalData
VR Failures	VR_1	GPU[0-7] VR Fault	Only Capable for SXM_PWR_GOOD through DFV/DFT logic. Please refer to FPGA page SR#11.(3608230)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Power for GPU is derived from one or more VRâ€™s present on BaseBoard. This condition represents failure of VR	ES			System QA			I2C1_ALERT_N	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId} 
  

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} Power Status
'	'[Amar] HMC can access same infomation as BMC
[Amar] DC cycle, if condition removed, then it is VR themal related. If not then it is hard failure. 

4/21 Note: Power cycle the BaseBoard from host BMC.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} PowerGood", "Abnormal Power Change"]	{GPUId} Power Status
VR Failures	VR_2	BaseBoard Standby power Fault		Frans Fourie US	PS	{Amar] There are multiple STBY PWR VRs if one of them does not come up then FPGA is dead and alerts or information is provided by FPGA. In this case there is a new STBY_MON circuit power by 48V directly which can be read over I2C1 (7b addr 0x20) to  indentify which  STBY supply did not power up. This circuit will only be avialble (i.e. I2C addr 0x20) only if STBY power is down.	QS			HW Validation(Frans Fouri)			FPGA_READY 	Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	'[Amar] No access from HMC

4/21 Note:  
- midplane standby enabled should be driven high from host to turn on.
- address 0x20 should be de-asserted

4/26 Note:
Recovery(WIP) - If FPGA ready is not up (mechanism - TBD), power cycle the BaseBoard from host BMC. 

- Amar to check if debug info can be made available

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.)'									
VR Failures	VR_3	Retimer[0-7] VR fault	Capable through DFV/DFT logic. Please refer to FPGA page SR#16(3609410)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] Retimers have three main PWR supplies (0.9V, 1.2V, and 1.8V)). Each of these supplies has its owen PG signal supplied to FPGA.	ES			System QA				Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 
  

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{RetimerId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{RetimerId} 0V9 Abnormal change
{RetimerId} 1V8 VDD Abnormal change
{RetimerId} 1V8 LDO Abnormal change
'	'[Amar] HMC can access same infomation as BMC
[Amar] Retimer 0.9V and 1.2V VR are dierectly connected to FPGA via I2C.

4/21 Note: Power cycle the BaseBoard from host BMC.'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{RetimerId} PowerGood", "Abnormal Power Change"]	'{RetimerId} 0V9 Abnormal change
{RetimerId} 1V8 VDD Abnormal change
{RetimerId} 1V8 LDO Abnormal change
'
VR Failures	VR_4	GPU[0-7] ERoT VR fault		Frans Fourie US	PS	'GPU EROT power fault causing AP_RESET# to assert, causing GPU to hang
[Amar] EROT_FATAL_ERROR_N connected to FPGA shoul also be asserted'	QS			HW Validation(Frans Fouri)			'Passive GPU Telemetry failure; MCTP Enumeration failure
[Amar] I2C1_ALERT_N'	'Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 
'	No HMC access.	'[Amar] No HMC access

4/21 Note: ERoT is part of standby power.

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.) '	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_GPUId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_6	NVSwitch[0-3] ERoT VR fault		Frans Fourie US	PS	[Amar] If ERoT VR does not come up, then STBY PRW will not come up.	ES			HW Validation(Frans Fouri)			'Passive NVSW Telemetry failure
[Amar] FPGA_READY de-asserted'	'Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 
'	No HMC access.	'[Amar] No HMC access

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.) '	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_NVSwitchId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_7	NVSwitch[0-3] VR fault	Capable through DFV/DFT logic. Please refer to FPGA page SR#12(3609327)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] NVSW has sevral power supplies: VDD, DVDD, HVDD, 1.8V. All of which has its own PG signal connected to FPGA. It also has a combined  VR fault signal for VDD and DVDD, and HVDD. 	ES			System QA			'I2C2_ALERT_N
[Amar] VR PG and VR FAULT connected to FPGA.'	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
  

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change
'	'[Amar] HMC can access same information
[Amar] DC cycle if conditione removed then thermal of over current.

4/21 Note: Power cycle the BaseBoard from host BMC.'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PowerGood", "Abnormal Power Change"]	'{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change'
VR Failures	VR_8	PCIe Switch ERoT VR fault		Frans Fourie US	PS	[Amar] If ERoT VR does not come up, then STBY PRW will not come up.	QS			HW Validation(Frans Fouri)			'[Amar] FPGA_READY de-asserted
'	'Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 
'	No HMC access.	'[Amar] No HMC access

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.) '	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_PCIeSwitchId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_9	PCIe Switch VR fault	Capable through DFV/DFT logic. Please refer to FPGA page SR#15(3609363)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] PEX_SW has  0.84V and shares SYS_1.8V. If SYS_1.8V is not up then BASE_PWR_OK  not asserted. Each of these VRs has PG connected to  FPGA.	ES			System QA			'I2C2_ALERT_N
[Amar] BASE_PWR_OK'	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 
  

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{PCIeSwitchId} 0V8 Abnormal change
'	'[Amar] HMC has access to same information
[Amar] DC cycle if conditione removed then thermal of over current.

4/21 Note: Power cycle the BaseBoard from host BMC.'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PowerGood", "Abnormal Power Change"]	{PCIeSwitchId} 0V8 Abnormal change
VR Failures	VR_10	BaseBoard HSC[0-11] fault(Thermtrip and PG)	Capable through DFV/DFT logic. Please refer to FPGA page SR#13(3609347)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] All HSCs PG are connected  to FPGA. 	ES			System QA			'I2C2_ALERT_N
'	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
 /redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD) 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HSCId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{HSCId} detailed alert status
'	'4/21 Note: Power cycle the BaseBoard from host BMC.

4/27 Note
HSC0-9 - (NVSwitch/GPU) try to power cycle, if problem persists, need RMA

HSC10 - (HERM) Not in current scope and need further evaluation. Check with Vishal.

HSC11 - FPGA VR fault, need RMA'	'For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}'	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HSCId} PowerGood", "Abnormal Power Change"]	{HSCId} detailed alert status
VR Failures	VR_11	FPGA VR fault		Frans Fourie US	PS	[Amar] If any FPGA VR is down then STBY power is goes down and FPGA_READY is deasserted	QS			HW Validation(Frans Fouri)			FPGA_READY 	'Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 
'	No HMC access.	'[Amar] No HMC access

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.) '	/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_12	FPGA ERoT VR fault		Frans Fourie US	PS	[Amar] If ERoT VR does not come up, then STBY PRW does come up.	QS			HW Validation(Frans Fouri)			FPGA_READY 	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 	No HMC access.	'[Amar] No HMC access

5/4 Backup:
(TBD- Check the BaseBoard standby monitor from host BMC. Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.) '	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_FPGAId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_13	HMC VR fault	Capable through DFV/DFT logic. Please refer to FPGA page SR#17(3609426)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] HMC PG is connected to FPGA	QS			System QA			HMC_PG	'It can be detected by HMC_PG not asserted (from FPGA).

Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	No HMC access.		/redfish/v1/Managers/{ManagerId}		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HSCId} PowerGood", "Abnormal Power Change"]	
VR Failures	VR_14	System VR fault	Capable through DFV/DFT logic. Please refer to FPGA page SR#14(3609357)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	[Amar] SYS_3V3, SYS_1V8 PG is connected to FPGA	QS			System QA			I2C2_ALERT_N	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId} 
 /redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD) 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{SysVRId} PowerGood", "Abnormal Power Change"]

and update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
SysVR 3V3 Abnormal change
SysVR 1V8 Abnormal change
'	'4/21 Note: Power cycle the BaseBoard from host BMC. Check baseboard power enable signal. All the devices are not on.

HMC to identify which SysVR has fault. "Compnent SysVR_X has fault" - Add to Recovery?

Component and BaseBoard (System) - Critical

Except for HMC/GPU (field-replaceable) --> BaseBoard marks as Critical

If SysVR fault causes HMC not operational, HMC will not report the error.'	/redfish/v1/Chassis/{BaseboardId}	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{SysVRId} PowerGood", "Abnormal Power Change"]	'SysVR 3V3 Abnormal change
SysVR 1V8 Abnormal change'
ERoT failures	ERoT_1	Heartbeat failure - HMC	Stop the MCTP-over-SPI service (systemctl stop mctp-spi-ctrl) anytime when the system is running. The Glacier would get timed out and reset it.	Mahendra Y	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects a periodic heartbeat signal from AP. Glacier will reset AP if fails to receive the signal for a certain timout value 	QS	Create a test case that runs on RPi to inject error VDM to Glacier		 System QA		3586461		HostBMC to check HMC EROT for report. HostBMC can also extract EROT log from the SelfTest after HMC recovered and send to NVIDIA.	No HMC access.	'HMC log after subsequent reset.

Internal log accessible:
1. VDM command - already supported in HMC
2. I2C command- already supported in HMC

3. SPDM - only the latest measurement 
(AI-Vishal: check with VK if this is implemented)

5/3 Note: Kun to check with Terry and HMC team any implementation concern.
5/3 Note: Defer HMC/FPGA failure to QS0

5/4 Note: Kun to check with Terry for the last AP boot status support.

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.
Recovery => HostBMC to check AP EROT for report. HostBMC can also extract EROT log from the SelfTest after HMC recovered and send to NVIDIA.'			/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Firmware", "Heartbeat Failure"]	
ERoT failures	ERoT_2	Heartbeat failure - FPGA	See instructions in 3636093	Leon	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects a periodic heartbeat signal from AP. Glacier will reset AP if fails to receive the signal for a certain timout value 	QS	See instructions in 3636093		System QA		3586461		HostBMC to check FPGA EROT for report. HostBMC can also extract EROT log from the SelfTest after FPGA recovered and send to NVIDIA.	No HMC access.	'4/20 Note: 
HMC is up. Which signal goes down? How HMC recover FPGA?

No I2C from HMC to Glacier. Need host BMC to do recovery.

HMC logs ready_signal.

5/3 Note: Defer HMC/FPGA failure to QS0

5/4 Note: Kun to check with Terry for the last AP boot status support. Check FPGA_READY?

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.
Or,
MessageArgs => ["{FPGAId} Firmware", "Communication Failure"]'	/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} Firmware", "Heartbeat Failure"]	
ERoT failures	ERoT_3	Boot completed failure - HMC	'systemctl disable mctp-spi-ctrl and reboot.

Once done, systemctl enable mctp-spi-ctrl and reboot.'	Mahendra Y	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects AP sends BootComplted signal to Glacier after it boots up. Glacier will reset AP if fails to receive the signal for a certain timout value 	QS	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		HostBMC to check HMC EROT for report. HostBMC can also extract EROT log from the SelfTest after HMC recovered and send to NVIDIA.	No HMC access.	'4/20 Note:
Same as HMC heartbeat failure.

5/3 Note: Defer HMC/FPGA failure to QS0

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.'			/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Firmware", "Boot Complete Failure"]	
ERoT failures	ERoT_4	Boot completed failure - FPGA	See instructions in 3636093	Leon Lixingyu c	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects AP sends BootComplted signal to Glacier after it boots up. Glacier will reset AP if fails to receive the signal for a certain timout value 	QS	See instructions in 3636093		System QA		3586461		HostBMC to check FPGA EROT for report. HostBMC can also extract EROT log from the SelfTest after FPGA recovered and send to NVIDIA.	No HMC access.	'HMC logs ready_signal.

5/3 Note: Defer HMC/FPGA failure to QS0

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.
Or,
MessageArgs => ["{FPGAId} Firmware", "Communication Failure"]'	/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} Firmware", "Boot Complete Failure"]	
ERoT failures	ERoT_5	Boot completed failure - GPU[0-7]	Special VBIOS image(3636138)	Kshitij Soni	Sat May 07 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects AP sends BootComplted signal to Glacier after it boots up. Glacier will reset AP if fails to receive the signal for a certain timout value 	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Firmware", "Boot Complete Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	'4/20 Note:
Internal log accessible:
1. VDM command - already supported in HMC
2. I2C command- already supported in HMC'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Firmware", "Boot Complete Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_6	Boot completed failure - LS10[0-3]	Special LS10 FW(3636702)	Kshitij Soni 	Sat May 07 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Glacier expects AP sends BootComplted signal to Glacier after it boots up. Glacier will reset AP if fails to receive the signal for a certain timout value 	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} Firmware", "Boot Complete Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'		'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} Firmware", "Boot Complete Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_7	Boot completed failure - PCIe Switch	Special MCHP FW 	Raghupathy K	 	Glacier expects AP sends BootComplted signal to Glacier after it boots up. Glacier will reset AP if fails to receive the signal for a certain timout value 	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} Firmware", "Boot Complete Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'		'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} Firmware", "Boot Complete Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_8	Secure boot failure - HMC	Non signed HMC image will be provided for the test. This image needs to be programmed using i2c-fw-update tool.	Mahendra Y	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'Glacier authenticates FW image on SPI and releases AP_RESET pin if passes. AP won''t not allows to boot if authentication failed'	QS	Create a test case that runs on RPi to flash unsigned image  to Glacier		System QA		3586461		HostBMC to check HMC EROT for report. HostBMC can also extract EROT log from the SelfTest after HMC recovered and send to NVIDIA.	No HMC access.	'4/20 Note: (same as heartbeat/boot completed failure)

5/3 Note: Defer HMC/FPGA failure to QS0

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.'			/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Firmware", "Secure Boot Failure"]	
ERoT failures	ERoT_9	Secure boot failure - FPGA	See instructions in 3636093	Leon	Wed May 04 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'Glacier authenticates FW image on SPI and releases AP_RESET pin if passes. AP won''t  boot if authentication failed'	QS	See instructions in 3636093		System QA		3586461		HostBMC to check FPGA EROT for report. HostBMC can also extract EROT log from the SelfTest after FPGA recovered and send to NVIDIA.	No HMC access.	'4/20 Note: (same as heartbeat/boot completed failure)

HMC logs ready_signal.

5/3 Note: Defer HMC/FPGA failure to QS0

5/5 Terry: no support of last AP boot status in Glacier.
Kun: Checking with Ron about the last boot complete instance meaning in SPDM.

Suggestions,
HMC Behavior => No HMC access.
Or,
MessageArgs => ["{FPGAId} Firmware", "Communication Failure"]'	/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} Firmware", "Secure Boot Failure"]	
ERoT failures	ERoT_10	Secure boot failure - GPU[0-7]	unsigned image(3636732)	Kshitij Soni	Sat May 07 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Firmware", "Secure Boot Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: (same as boot completed failure)	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Firmware", "Secure Boot Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_11	Secure boot failure - LS10[0-3]	unsigned image(3636732)	Kshitij Soni	Sat May 07 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} Firmware", "Secure Boot Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: (same as boot completed failure)	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} Firmware", "Secure Boot Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_12	Secure boot failure - PCIe Switch	unsigned image	Terry Hsieh	Sat May 07 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	ES	Create a test case that runs on RPi to inject error VDM to Glacier		System QA		3586461		eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} Firmware", "Secure Boot Failure"]

and update Resolution of redfish event log to: 
eROT will try to recover AP by a reset/reboot. If there is still a problem, AP FW needs to be re-flashed.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: (same as boot completed failure)	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} Firmware", "Secure Boot Failure"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_13	VR fault - HMC	No	 		Voltage regulator failure is a HW failure	QS	may need HW rework to remove AP SPI to check 		HW validation		 		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	4/20 Note: Will finalize in VR tab									
ERoT failures	ERoT_14	VR fault - FPGA	No			Voltage regulator failure is a HW failure	QS	may need HW rework to remove AP SPI to check 		HW validation		 		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	4/20 Note: Will finalize in VR tab	/redfish/v1/Chassis/{ERoTId}	'/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId}
(TBD)'	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent		
ERoT failures	ERoT_15	VR fault - GPU[0-7]	No	 		Voltage regulator failure is a HW failure	QS	may need HW rework to remove AP SPI to check 		HW validation		 		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	4/20 Note: Will finalize in VR tab	/redfish/v1/Chassis/{ERoTId}	'/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId}
(TBD)'	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent		
ERoT failures	ERoT_16	VR fault - LS10[0-3]	No	 		Voltage regulator failure is a HW failure	ES	may need HW rework to remove AP SPI to check 		HW validation		 		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	4/20 Note: Will finalize in VR tab	/redfish/v1/Chassis/{ERoTId}	'/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId}
(TBD)'	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent		
ERoT failures	ERoT_17	VR fault - PCIe Switch	No	 		Voltage regulator failure is a HW failure	ES	may need HW rework to remove AP SPI to check 		HW validation		 		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	No HMC access.	4/20 Note: Will finalize in VR tab	/redfish/v1/Chassis/{ERoTId}	'/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId}
(TBD)'	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent		
ERoT failures	ERoT_18	SPI flash error - HMC	Remove the Flash and short the SPI pins	Shariq Ali	PS	All SPI flashes shall be health for both Glacier and APs to R/W. Glacier cannot work normally if SPI failed	PS	may need HW rework to remove AP SPI to check 		HW validation		 		HostBMC to check HMC_READY and HMC EROT_FATAL signal, query the HMC EROT log for further debugging. Cordon HGX server from the cluster for RMA evaluation.	No HMC access.	'4/20 Note: Image authentication will fail and depends on single or double flash faults, the mediation will differ. (same as heartbeat failure)

5/3 Note: Defer HMC/FPGA failure to QS0

5/4 Note: HostBMC to check HMC_READY and HMC EROT_FATAL signal, query the HMC EROT log for further debugging. Cordon HGX server from the cluster for RMA evaluation.'			/redfish/v1/Managers/{ManagerId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Firmware", "SPI Flash Error"]	
ERoT failures	ERoT_19	SPI flash error - FPGA	 ERot_18 test result will be extrapolated for this case	 		All SPI flashes shall be health for both Glacier and APs to R/W. Glacier cannot work normally if SPI failed	PS	may need HW rework to remove AP SPI to check 		HW validation		 		HostBMC to check FPGA_READY and FPGA EROT_FATAL signal, query the FPGA EROT log for further debugging. Cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{FPGAId} Firmware", "Communication Failure"]

and update Resolution of redfish event log to: 
HostBMC to check FPGA_READY and FPGA EROT_FATAL signal, query the FPGA EROT log for further debugging. Cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
'	'5/3 Note: Defer HMC/FPGA failure to QS0

5/4 Note: 
MessageArgs => ["{FPGAId} Firmware", "Communication Failure"]
Recovery => HostBMC to check FPGA_READY and FPGA EROT_FATAL signal, query the FPGA EROT log for further debugging. Cordon HGX server from the cluster for RMA evaluation.'	/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} Firmware", "Communication Failure"]	
ERoT failures	ERoT_20	SPI flash error - GPU[0-7]	ERot_18 test result will be extrapolated for this case 	 		All SPI flashes shall be health for both Glacier and APs to R/W. Glacier cannot work normally if SPI failed	PS	may need HW rework to remove AP SPI to check 		HW validation		 		Cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Firmware", "SPI Flash Error"]

and update Resolution of redfish event log to: 
Cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: Redundnacy should be supported.	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Firmware", "SPI Flash Error"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_21	SPI flash error - LS10[0-3]	ERot_18 test result will be extrapolated for this case			All SPI flashes shall be health for both Glacier and APs to R/W. Glacier cannot work normally if SPI failed	PS	may need HW rework to remove AP SPI to check 		HW validation		 		Cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} Firmware", "SPI Flash Error"]

and update Resolution of redfish event log to: 
Cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'		'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} Firmware", "SPI Flash Error"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_22	EROT recovery - HMC	Terry to share steps with QA	RHys Hou	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	BMC should be able to recover HMC Glacier if EC_FW corrupted	QS	Have recovery tools on RPi already		System QA		3586461		EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	No HMC access.										
ERoT failures	ERoT_23	EROT recovery - FPGA	Terry to share steps with QA	RHys Hou	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	BMC should be able to recover FPGA Glacier if EC_FW corrupted	QS	Have recovery tools on RPi already		System QA		3586461		EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	No HMC access.	'4/20 Note: TBD - check if ERoT_Fatal error is connected to HMC. If yes, log error, and mark ERoT status appropriately.

MessageArgs:
["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]

Kun - check with Terry how to differentiate ERoT recovery vs ERoT_Fatal. How to recover from both of the scenarios?

5/5 This should never happen unless user assert EROT_RECOV and reboot EROT on purpose.
Once it happens,
Recovery => HostBMC deassert EROT_RECOV and reboot EROT. If proplem persists, cordon HGX server from the cluster for RMA evaluation.

When EROT_RECOV asserted, the AP won''t work.
(Applies to every EROT recovery faults above and below.)

HMC Behavior => No HMC access.

Check with Amar,
If FPGA EROT is in recovery then FPGA will be held in reset by EROT which means FPGA_READY will be de-asserted which HMC can detect. Also, If EROT had problem booting its EC_FW then FPGA_EROT_FATAL_ERROR_N will be asserted which HMC can detect. Only BMC has access to FPFA_EROT RESET and RECOV signals. If BMC is initiating such transaction then it could notify HMC via I2C1/2 or HMC itself can snoop on any transaction addressed 0x52/53 on I2C1.
only BMC has access to FPGA_EROT RESET/RECOV. HMC can''t initiate FPGA_EROT recovery process, so BMC will have to notify HMC if such process occurs. At least this was not a requirement in arch.
No HMC can''t see FPGA_EROT on I2C3.
Maybe we can add an EROT in recovery to be part of EROT_FATAL assertion condition.'	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoTId} Firmware", "ERoT Recovery"]	
ERoT failures	ERoT_24	EROT recovery - GPU[0-7]	Terry to share steps with QA	RHys Hou	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	BMC should be able to recover GPU Glacier if EC_FW corrupted	QS0	Have recovery tools on RPi already		System QA		3586461		EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoTId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoTId} Firmware", "ERoT Recovery"]

and update Resolution of redfish event log to: 
EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: TBD - check if ERoT_Fatal error is connected to HMC. If yes, log error, and mark ERoT status appropriately.	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoTId} Firmware", "ERoT Recovery"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_25	EROT recovery - LS10[0-3]	Terry to share steps with QA	RHys Hou	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	BMC should be able to recover LS10 Glacier if EC_FW corrupted	QS0	Have recovery tools on RPi already		System QA		3586461		EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoTId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoTId} Firmware", "ERoT Recovery"]

and update Resolution of redfish event log to: 
EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: TBD - check if ERoT_Fatal error is connected to HMC. If yes, log error, and mark ERoT status appropriately.	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoTId} Firmware", "ERoT Recovery"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_26	EROT recovery - PCIe Switch	Terry to share steps with QA	RHys Hou	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	BMC should be able to recover Switch Glacier if EC_FW corrupted	QS0	Have recovery tools on RPi already		System QA		3586461		EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoTId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoTId} Firmware", "ERoT Recovery"]

and update Resolution of redfish event log to: 
EROT is in recovery mode, and HostBMC need to deassert EROT_RECOV and reboot the device. If proplem persists, cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	4/20 Note: TBD - check if ERoT_Fatal error is connected to HMC. If yes, log error, and mark ERoT status appropriately.	/redfish/v1/Chassis/{ERoTId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoTId} Firmware", "ERoT Recovery"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_27	MCTP runtime failures - HMC	'1) TID-30 to TID-34 in this sheet

2) systemctl disable mctp-demux-daemon at various stages of FW update. Redfish should show appropriate error messages.

3) systemctl disable mctp-demux-daemon at various stages of SPDM Get MEasurements. Redfish should show appropriate error messages.

4) systemctl disable mctp-ctrl after HMC boot and attempt FW update. Redfish should show appropriate error messages.

5) systemctl disable mctp-ctrl. Reboot HMC and attempt FW update. Redfish should show appropriate error messages.

6) Edit /etc/default/mctp and change the bindinfo argument. Reboot the HMC and attempt FW update. Redfish should show appropriate error messages.
'	Tom	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	MCTP is the fundemental communication protocal between AP and Glacier. All PLDM/SPDM FW update or VDM signals/payloads are carried by the protocol.	QS	Create negative test cases that runs on RPi to mimic MCTP failure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_HMCId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_HMCId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'	'4/20 Note:  Glacier retry 3 times for fw update, otherwise fail the fw update/EID => RMA.

AP should retry for VDM command - collecting log

Analyze the Glacier logs for root cause.

Severity: OK(informational)

Kun - how to extract MCTP/PLDM error from FPGA?
'	/redfish/v1/Chassis/{ERoT_HMCId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_HMCId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_28	MCTP runtime failures - FPGA	'1) TID-30 to TID-34 in this sheet

2) systemctl disable mctp-demux-daemon at various stages of FW update. Redfish should show appropriate error messages.

3) systemctl disable mctp-demux-daemon at various stages of SPDM Get MEasurements. Redfish should show appropriate error messages.

4) systemctl disable mctp-ctrl after HMC boot and attempt FW update. Redfish should show appropriate error messages.

5) 4) systemctl disable mctp-ctrl. Reboot HMC and attempt FW update. Redfish should show appropriate error messages.'	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	MCTP is the fundemental communication protocal between AP and Glacier. All PLDM/SPDM FW update or VDM signals/payloads are carried by the protocol.	QS	Create negative test cases that runs on RPi to mimic MCTP failure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_FPGAId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_FPGAId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_FPGAId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_FPGAId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_29	MCTP runtime failures - GPU[0-7]	'1) TID-30 to TID-34 in this sheet

2) systemctl disable mctp-demux-daemon at various stages of FW update. Redfish should show appropriate error messages.

3) systemctl disable mctp-demux-daemon at various stages of SPDM Get MEasurements. Redfish should show appropriate error messages.

4) systemctl disable mctp-ctrl after HMC boot and attempt FW update. Redfish should show appropriate error messages.

5) systemctl disable mctp-ctrl. Reboot HMC and attempt FW update. Redfish should show appropriate error messages.

6) Edit /etc/default/mctp and change the bindinfo argument. Reboot the HMC and attempt FW update. Redfish should show appropriate error messages.
'	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	MCTP is the fundemental communication protocal between AP and Glacier. All PLDM/SPDM FW update or VDM signals/payloads are carried by the protocol.	ES	Create negative test cases that runs on RPi to mimic MCTP failure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_GPUId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_GPUId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_GPUId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_GPUId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_30	MCTP runtime failures - LS10[0-3]	'1) TID-30 to TID-34 in this sheet

2) systemctl disable mctp-demux-daemon at various stages of FW update. Redfish should show appropriate error messages.

3) systemctl disable mctp-demux-daemon at various stages of SPDM Get MEasurements. Redfish should show appropriate error messages.

4) systemctl disable mctp-ctrl after HMC boot and attempt FW update. Redfish should show appropriate error messages.

5) systemctl disable mctp-ctrl. Reboot HMC and attempt FW update. Redfish should show appropriate error messages.

6) Edit /etc/default/mctp and change the bindinfo argument. Reboot the HMC and attempt FW update. Redfish should show appropriate error messages.
'	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	MCTP is the fundemental communication protocal between AP and Glacier. All PLDM/SPDM FW update or VDM signals/payloads are carried by the protocol.	ES	Create negative test cases that runs on RPi to mimic MCTP failure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_NVSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_NVSwitchId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_NVSwitchId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_NVSwitchId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_31	MCTP runtime failures - PCIe Switch	'1) TID-30 to TID-34 in this sheet

2) systemctl disable mctp-demux-daemon at various stages of FW update. Redfish should show appropriate error messages.

3) systemctl disable mctp-demux-daemon at various stages of SPDM Get MEasurements. Redfish should show appropriate error messages.

4) systemctl disable mctp-ctrl after HMC boot and attempt FW update. Redfish should show appropriate error messages.

5) systemctl disable mctp-ctrl. Reboot HMC and attempt FW update. Redfish should show appropriate error messages.

6) Edit /etc/default/mctp and change the bindinfo argument. Reboot the HMC and attempt FW update. Redfish should show appropriate error messages.
'	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	MCTP is the fundemental communication protocal between AP and Glacier. All PLDM/SPDM FW update or VDM signals/payloads are carried by the protocol.	ES	Create negative test cases that runs on RPi to mimic MCTP failure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_PCIeSwitchId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_PCIeSwitchId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_PCIeSwitchId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_32	PLDM runtime failures - HMC	TID-53 to TID-73 in this sheet	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	PLDM is a Platform Level Data Model, aims for AP/EC_FW update to Glacier	ES	Create negative test cases that runs on RPi to mimic PLDMfailure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_HMCId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_HMCId} Firmware", "MCTP Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_HMCId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_HMCId} Firmware", "MCTP Runtime Failure"]	
ERoT failures	ERoT_33	PLDM runtime failures - FPGA	TID-53 to TID-73 in this sheet	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	PLDM is a Platform Level Data Model, aims for AP/EC_FW update to Glacier	ES	Create negative test cases that runs on RPi to mimic PLDMfailure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_FPGAId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_FPGAId} Firmware", "PLDM Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_FPGAId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_FPGAId} Firmware", "PLDM Runtime Failure"]	
ERoT failures	ERoT_34	PLDM runtime failures - GPU[0-7]	TID-53 to TID-73 in this sheet	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	PLDM is a Platform Level Data Model, aims for AP/EC_FW update to Glacier	ES	Create negative test cases that runs on RPi to mimic PLDMfailure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_GPUId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_GPUId} Firmware", "PLDM Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_GPUId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_GPUId} Firmware", "PLDM Runtime Failure"]	
ERoT failures	ERoT_35	PLDM runtime failures - LS10[0-3]	TID-53 to TID-73 in this sheet	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	PLDM is a Platform Level Data Model, aims for AP/EC_FW update to Glacier	ES	Create negative test cases that runs on RPi to mimic PLDMfailure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_NVSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_NVSwitchId} Firmware", "PLDM Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_NVSwitchId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_NVSwitchId} Firmware", "PLDM Runtime Failure"]	
ERoT failures	ERoT_36	PLDM runtime failures - PCIe Switch	TID-53 to TID-73 in this sheet	Tom/Deepak	Wed Aug 10 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	PLDM is a Platform Level Data Model, aims for AP/EC_FW update to Glacier	ES	Create negative test cases that runs on RPi to mimic PLDMfailure		System QA		3586461		BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_PCIeSwitchId} Firmware", "PLDM Runtime Failure"]

and update Resolution of redfish event log to: 
BaseBoard components will retry if encounters errors. If problem persists, analyze FPGA log or ERoT log.

and AdditionalData:
'		/redfish/v1/Chassis/{ERoT_PCIeSwitchId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_PCIeSwitchId} Firmware", "PLDM Runtime Failure"]	
ERoT failures	ERoT_37	FW Update with WP engaged - HMC	 Can be done from BMC	Mahendra Y	Fri Jul 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	A physical WP jumper should be available for HMC. Glacier cannot update SPI if WP is enabled	QS	need a manual test since WP jump is not controlled by Glacier		System QA		3586461		If WP enabled, Glacier/AP shall not be able to update SPI. This is a HW protection.	'1. Change HealthRollup for following URIs 
 n/a 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HMCId} Firmware", "WriteProtected"]

and update Resolution of redfish event log to: 
If WP enabled, Glacier/AP shall not be able to update SPI. This is a HW protection.

and AdditionalData:
'	'Log only

4/20 Note:  Which Glacier is not aware of WP signal and fall into background copy operation.

5/3 Note:
Defer to QS0'	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Firmware", "WriteProtected"]	
ERoT failures	ERoT_38	FW Update with WP engaged - GPU[0-7]/LS10[0-3]		Terry Hsieh		A physical WP jumper might be available for all GPU. Glacier cannot update SPI if WP is enabled	QS	need a manual test since WP jump is not controlled by Glacier		System QA		3586461		If WP enabled, Glacier/AP shall not beable to update SPI. This is a HW protection.	'1. Change HealthRollup for following URIs 
 n/a 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{APId} Firmware", "WriteProtected"]

and update Resolution of redfish event log to: 
If WP enabled, Glacier/AP shall not beable to update SPI. This is a HW protection.

and AdditionalData:
'	'Log only

4/20 Note:  Which Glacier is not aware of WP signal and fall into background copy operation.'	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{APId} Firmware", "WriteProtected"]	
ERoT failures	ERoT_39	any other WP?		Terry Hsieh			QS					3586461													
ERoT failures	ERoT_40	Switch EEPROM Error	'Flash a bad image to the EEPROM.  Manual test, maybe even something we''d need to do on a non-EROT board.  If we want to see EROT do a recovery here, then I guess we''d need to sign a purposefullyh corrupt EEPROM image we could write?'	Terry Hsieh		Retimer is unable to fully read its EEPROM via I2C during its boot-up process. This will result in the retimer not configuring itself properly and no PCIe link being established.	QS			System QA		3586461		Cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} Firmware", "SPI Flash Error"]

and update Resolution of redfish event log to: 
Cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
{ERoTId} BootStatusCode
{ERoTId} Log'	'[AO] There is no HW signal from PCIe Switch to indicate boot failure, but FPGA should be able to get indirect information of PCIe Switch Glacier or check telemetry bus to see if it is up after release.  HMC can then get access to this information via I2C/PCIe.

Same as SPI Flash Error. Recovery => Need RMA?'	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/UpdateService/FirmwareInventory/{SoftwareInventoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	MCTP	["{PCIeSwitchId} Firmware", "SPI Flash Error"]	'{ERoTId} BootStatusCode
{ERoTId} Log'
ERoT failures	ERoT_41	GPU[0-7] ERoT in Recovery Mode	Special EC_FW image with incorrect keys put into both EC_FW slots	Terry Hsieh		[Amar] GPU failure to boot, PWR Enabled, and PG is asserted.	QS					3586461	Passive I2C Scan 0x53	Same as ERoT_24	Same as ERoT_24	[Amar] No HMC access									
ERoT failures	ERoT_42	ERoT HMC restart notify failure	Edit /lib/systemd/system/mctp-restart-notify.service.d/mctp-restart-notify-hgx.conf and comment out/remove the line that invokes mctp-vdm-util and reboot HMC. HMC wil not reboot (no flash access). HMC Heartbeat should  get trigerred and HMC will boot from the other side.	Tom Joseph			QS																		
ERoT failures	ERoT_43	HMC FPGA ready/not ready	'systemctl start nvidia-fpga-notready. Perform FW update. Redfish show should relevant error messages.

systemctl stop nvidia-fpga-notready should recover FW update capability.'				QS																		
ERoT failures	ERoT_44	Reboot HMC in the middle of Vulcan FW update	Reboot HMC in the middle of Vulcan FW update - FW update should work post reboot.				QS																		
ERoT failures	ERoT_45	Impact specific ERoT in the middle of FW update	Tom Joseph IN				QS																		
ERoT failures	ERoT_46	EROT internal flash error - all APs (exclude HMC)					QS							HostBMC to recovery the EROT. If proplem persists, cordon HGX server from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{ERoT_APId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]

and update Resolution of redfish event log to: 
HostBMC to recovery the EROT. If proplem persists, cordon HGX server from the cluster for RMA evaluation.

and AdditionalData:
'	'4/20 Note: ERoT_Fatal will be triggered. - physical signal

HMC has connection to this signal? change health to ERoT. (exclude HMC ERoT)

TBD - check if ERoT_Fatal error is connected to HMC. If yes, log error, and mark erot status appropriately.

MessageArgs:
["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]
e.g.
ERoT_GPUId -> ERoT_GPU_SXM_1 - ERoT_GPU_SXM_8
ERoT_NVSwitchId -> ERoT_NVSwitch0 - ERoT_NVSwitch3

5/5 EROT_FATAL will assert in this case.
MessageArgs => ["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]
Recovery => HostBMC to recovery the EROT. If proplem persists, cordon HGX server from the cluster for RMA evaluation.'	/redfish/v1/Chassis/{ERoT_APId}		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]	
GPU Failures	GPU_1	GPU[0-7] Over Temp	'Temp faking avaiable.
Capable through FPGA DFV/DFT logic. Please refer to FPGA page SR#5(3592884)'	'Leon/Amanda 
'	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s, GPU will shutdown autonomously.	ES			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{GPUId} Temperature", "{UpperFatal Threshold}"]

Update Resolution of redfish event log to:
Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.

and AdditionalData:
{GPUId} Temperature
{GPUId} Thermal Parameters

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'5/3 Note: 
Threshold will be included in Message/MessageArgs, available in QS0. 
AdditionalDataURI contains Temperature Reading and Thresholds.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{GPUId} Temperature", "{UpperFatal Threshold}"]	'{GPUId} Temperature
{GPUId} Thermal Parameters'
GPU Failures	GPU_2	GPU PWR BRAKE Asserted	get gpio_set command from Host BMC team	Mahendra Y		Host BMC has asserted GPU Power Brake signal (PWR_BRAKE_N). GPU clocks are throttled to one-fourth, and NVSwitch bandwidth is throttled without causing transaction timeout.	QS			System QA				De-assert the power brake on the host BMC.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} ThrottleReason", "HW Power Brake Slowdown"]

Update Resolution of redfish event log to:
De-assert the power brake on the host BMC.

and AdditionalData:


3. Create an XID event log. Accessible through:
n/a (no associated XID)'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} ThrottleReason", "HW Power Brake Slowdown"]	
GPU Failures	GPU_3	GPU[0-7] VR Failure	Only Capable for SXM_PWR_GOOD through FPGA DFV/DFT logic. Please refer to FPGA page SR#11.(3608230)	'Leon/Amanda 
'	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Power for GPU is derived from one or more VRâ€™s present on BaseBoard. This condition represents failure of VR	ES			System QA			I2C1_ALERT_N	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} PowerGood", "Abnormal Power Change"]

Update Resolution of redfish event log to:
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} Power Status

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'4/22 Note: Power cycle the BaseBoard. If it does not recover the failure, it is permanant damage.

Pramod to check with David Bachman for field diag support.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} PowerGood", "Abnormal Power Change"]	{GPUId} Power Status
GPU Failures	GPU_4	GPU[0-7] Row remapping failure	'Injection capabilities available. Needs Debug/Develop driver to test. Test only available internally.
GTest cmd is available'	Stephen Ma	Fri May 13 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] failed to successfully row remap a row, spare rows may have been exhausted.	QS	Yes		Mei Diao  (3577540)	3028849		NA	Cordon the HGX server node from the cluster for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Systems/{ComputerSystemId}/Memory/{GPUMemoryId}

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Memory", "Row-Remapping Failure"]

Update Resolution of redfish event log to:
Cordon the HGX server node from the cluster for RMA evaluation.

and AdditionalData:
{GPUId} Row remapping statistics

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	4/22 Note: Quarantine the HGX server for RMA analysis.	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Systems/{ComputerSystemId}/Memory/{GPUMemoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Memory", "Row-Remapping Failure"]	{GPUId} Row remapping statistics
GPU Failures	GPU_5	GPU[0-7] Row remapping pending	Injection capabilities available. Needs Debug/Develop driver to test. Test only available internally.GTest cmd is available	Stephen Ma		GPU[0-7] has dynamically blacklisted a row to avoid further access failure.  The row will be remapped after the GPU is reset.	QS	Yes		Mei Diao (3577540)	3052878			No immediate recovery required. Reset the GPU at next service window.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Systems/{ComputerSystemId}/Memory/{GPUMemoryId}

to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Memory", "Row-Remapping Pending"]

Update Resolution of redfish event log to:
No immediate recovery required. Reset the GPU at next service window.

and AdditionalData:
{GPUId} Row remapping statistics

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Systems/{ComputerSystemId}/Memory/{GPUMemoryId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Memory", "Row-Remapping Pending"]	{GPUId} Row remapping statistics
GPU Failures	GPU_6	GPU[0-7] SRAM Uncorrectable error	'Injection capabilities available. Needs Debug/Develop driver + HULK to test. Test only available internally.
Maynot be avl by ES - Stephen Ma will work on this'	Stephen Ma	Fri May 13 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] encountered internal SRAM Uncorrectable error.	ES	Yes		Mei Diao  (3577540)	3052879			Reset the GPU. If the GPU continues to exhibit the problem, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} SRAM", "Uncorrectable ECC Error"]

Update Resolution of redfish event log to:
Reset the GPU. If the GPU continues to exhibit the problem, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} SRAM Uncorrectable error count
{GPUId} SRAM Correctable error count

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'4/22 Note: Threshold of SRAM ucr error? 1 

'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} SRAM", "Uncorrectable ECC Error"]	'{GPUId} SRAM Uncorrectable error count
{GPUId} SRAM Correctable error count'
GPU Failures	GPU_7	GPU[0-7] DRAM Contained ECC Error	Injection capabilities available. Needs Debug/Develop driver + HULK to test. Test only available internally.	Stephen Ma	Fri May 13 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU [0-7] has experienced an uncorrectable ECC error that has impacted only the one application that was using the GPU when the error occurred.	ES			Mei Diao  (3577540)	3052880			Restart the affected application	'1. Change HealthRollup for following URIs 
n/a 
n/a

to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Memory", "Contained ECC Error"]

Update Resolution of redfish event log to:
Restart the affected application

and AdditionalData:
{GPUId} DRAM Uncorrectable error count
{GPUId} DRAM Correctable error count

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'4/22 Note: Pending row-remapping?
Vishal to check.'	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Memory", "Contained ECC Error"]	'{GPUId} DRAM Uncorrectable error count
{GPUId} DRAM Correctable error count'
GPU Failures	GPU_8	GPU[0-7] DRAM Uncontained ECC Error	Injection capabilities available. Needs Debug/Develop driver + HULK to test. Test only available internally.	Stephen Ma	Fri May 13 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU [0-7] has experienced an uncorrectable ECC error that has impacted all all workloads on the GPU.	ES			Mei Diao  (3577540)	3052881			Reset the GPU and restart affected applications.	'1. Change HealthRollup for following URIs 
n/a 
n/a

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Memory", "Uncontained ECC Error"]

Update Resolution of redfish event log to:
Reset the GPU and restart affected applications.

and AdditionalData:
{GPUId} DRAM Uncorrectable error count
{GPUId} DRAM Correctable error count

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'		n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Memory", "Uncontained ECC Error"]	'{GPUId} DRAM Uncorrectable error count
{GPUId} DRAM Correctable error count'
GPU Failures	GPU_9	GPU[0-7] in Throttled state				GPU[0-7] clocks have been lowered to throttle the GPU due to one or more factors (e.g. the GPU has reached temperature, power limits, or other limiting factors)	QS			 System QA				No recovery required.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} ThrottleReason", {Throttle Reason}]

Update Resolution of redfish event log to:
No recovery required.

and AdditionalData:
{GPUId} ThrottleReason

3. Create an XID event log. Accessible through:
n/a (no associated XID)'	'4/22 Note: GPU Idle - Severity: OK (don''t log), others - Severity: Warning

Add note for Throttle reason here:
- User Defined Clocks
- Applications Clocks Settings
- SW Power Cap
- HW Slowdown
- HW Thermal Slowdown
- HW Power Brake Slowdown
- Sync Boost
- SW Thermal Slowdown Tavg
- SW Thermal Slowdown Tlimit
- Display Clock Setting

5/3 Note: the actual reason {Throttle Reason} will defer to QS0.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} ThrottleReason", {Throttle Reason}]	{GPUId} ThrottleReason
GPU Failures	GPU_10	GPU[0-7] PCIe link speed state change	Joseph Obedowski US	Jimmy Huang TW		The PCIe connection for GPU [0-7] has changed to a lower transfer rate due to recovery from link failures.	QS	Standard PCIe behavior	Standard PCIe behavior	 		3586773		Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} PCIe", "Abnormal Speed Change"]

Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} PCIe link speed

3. Create an XID event log. Accessible through:
n/a (no associated XID)'	'4/26 Note: 
How to determine? Change from default?
Target(trust the 1st value) vs current training. Check couple of times to make sure. 

Change Severity - warning.

Recovery - Check upstream PCIe switch''s health for invalid setting. Check links between PCIe switch and GPU in case of problem persist, reset GPU.

"AdditionalDataURI" or other property - links to selftest log. 
Kun to provide example
"AdditionalDataURI": "/redfish/v1/Systems/system/LogServices/EventLog/Entries/1/attachment",'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} PCIe", "Abnormal Speed Change"]	{GPUId} PCIe link speed
GPU Failures	GPU_11	GPU[0-7] PCIe link width state change	N/A	Joseph O		The PCIe connection for GPU [0-7] has changed to utilize a lower number of lanes, (e.g. x1, x8) as part of recovery from PCIe failures.	QS	Standard PCIe behavior	Standard PCIe behavior	 		3586773		Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} PCIe", "Abnormal Width Change"]

Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} PCIe link width

3. Create an XID event log. Accessible through:
n/a (no associated XID)'	'4/26 Note:  same as above.

(Original Recovery) Reset the link.  If the problem affects multiple connections on the upstream PLX, isolate the server for RMA evaluation.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} PCIe", "Abnormal Width Change"]	{GPUId} PCIe link width
GPU Failures	GPU_12	GPU[0-7] PMU Microcontroller Halt	'Have a way to inject PMU halt via instrumentation builds which are special PMU builds. es, it is only enabled in the special DVS build called "Instrument Ucodes"
Assuming you are running one of those drivers, you can trigger a halt using tempsim with a specific temperature, give me a minute to double check what that was

tempsim or thermsensordebug applications
Once instrumented driver is running, from command prompt run thermsensordebug.exe --fake_temp_celsius 40 and that should halt PMU'	Jorge Ochoa	Fri May 13 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU [0-7] experienced an exception or halt on an internal microcontroller	ES			System QA				Reset the GPU. If the GPU continues to exhibit the problem, isolate the server for RMA evaluation.	TBD (HMC cannot detect this error)	'4/26 Note:
HMC not able to detect this failure.

Shrikant (copy Terence) - What breaks for PMU halt? How to monitor OOB? Is driver status(loaded/unloaded) is affected or return an error?

> Shrikant, I don''t think we have a query for the PMU state (unless the XID is able to be delivered via DEM)?

No, we don''t have any monitoring or query for the PMU state yet (but see below for timeout). The DEM delivery for XID 61 _should_ work now as it is the RM delivering it straight to FSP but it has not been fully implemented yet so there might unforeseen interactions in the driver which prevent that from happening.

> Is driver status(loaded/unloaded) affected or return an error?

The FSP server implements a timeout for hearing a response back from the PMU and will switch back to driver unloaded (Pre-OS) handling if a response doesn''t arrive within 80 ms of issuing the request and return ERR_AGAIN to the client.

This has not yet been stress tested in fault scenarios (crashes/halts), however.

By design if PMU crashes any driver dependent services would no longer be available i.e. capabilities will switch to Pre-OS set of capabilities. However, we haven''t been able to do fault injection testing for different failure scenarios yet e.g. deliberately crashing the PMU in the middle of serving a request or simulating a delayed, partial, or corrupted response etc. so there may still be undiscovered bugs in the current implementation.
'					The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_13	GPU[0-7] I2C Hang	'FPGA DFT can trigger the i2c3 alert .
Special test image will be created for this test case - Amanda can you verify with this test image
[Amanda] Per Rhys'' experiment and discussion with Leon, we could use DFV/DFT logic to force GPU SCL to low and send SMBPBI request to GPU to trigger SMBPBI/I2C timeout and FPGA would then assert I2C1(3)_ALERT_L to notify BMC. It would be covered by FPGA_29/FPGA_30 in FPGA page for FPGA behavior check. However, we would only check whether I2C1_ALERT_L & I2C3_ALERT_L output from FPGA are asserted, but not check whether BMC/HMC receives the alert.'	Leon L	 	When there is a i2c hang there will be a i2c3 alert that HMC can monitor	QS			Hardware validation				No recovery required since FPGA will recover the fault automatically	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: OK, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} I2C", "Hang"]

Update Resolution of redfish event log to:
No recovery required since FPGA will recover the fault automatically

and AdditionalData:


3. Create an XID event log. Accessible through:
n/a (no associated XID)'	'4/26 Note:
Kun to check with Leon for I2C hang detection logic.- NEW for Vulcan

5/2: [Kun] it''s from FPGA register table.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} I2C", "Hang"]	
GPU Failures	GPU_14	GPU[0-7] Physically Missing	Capable for GPU present toggle through FPGA DFV/DFT logic. Please refer to FPGA page SR#19.(3608397)	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] is physically removed from the system.	ES	Remove the GPU	Remove the GPU				FPGA raises an Interrupt if GPU is removed at runtime	Cordon the HGX server node for further diagnosis.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 


to Severity: Crtical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.1.ResourceStateChanged

and MessageArgs: 
["{GPUId}", "Absent"]

Update Resolution of redfish event log to:
Cordon the HGX server node for further diagnosis.

and AdditionalData:


3. Create an XID event log. Accessible through:
n/a (no associated XID)'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The state of resource `%1` has changed to %2.	ResourceEvent.1.1.ResourceStateChanged	ResourceEvent	["{GPUId}", "Absent"]	
GPU Failures	GPU_15	GPU [0-7] Inforom Corruption	N/A	Terence Riperda/Jim Van Veghel		GPU [0-7] has detected an formatting error in the inforom.	QS			System QA				Use NVIDIA GPU InfoROM File System Recovery Utility to recover. If the problem persists, restore infoROM to default settings using in-band tools such as nvflash.	'1. Change HealthRollup for following URIs 
n/a 
n/a

to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} InfoROM", "Corruption"]

Update Resolution of redfish event log to:
Use NVIDIA GPU InfoROM File System Recovery Utility to recover. If the problem persists, restore infoROM to default settings using in-band tools such as nvflash.

and AdditionalData:


3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'(Original Recovery) nvflash can be used to restore deafult inforom.  Inforom corruption is generally an indication of a software failure, and should be investigated with NVIDIA.

4/26 Note: 
Option1(first step) : Use "InfoROM recovery tool" to recover. Check with Neil T or AE
> NVIDIA GPU InfoROM File System Recovery Utility â€“ PID1084569
Option2: reset to default using nvflash'	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} InfoROM", "Corruption"]	
GPU Failures	GPU_16	GPU[0-7] Destination FLA Translation Error	'Internal test available to inject Destination FLA fault. test: OffChipErrorsPeerMemPrivAccess
 ./memoryFabric test suite (edited) '	Arvind G		GPU [0-7] has experienced an invalid access in the Fabric Linear Addressing translation tables.	QS0			Mei Diao   (3577546)				TBD	TBD	'Likely application/software issue.

4/26 Note: 
> Check with Terence for recovery of XID 98 and related documentation
XID 98 is an NVDEC error and basically identical to XIDs 83, 84, 88, 89, 96 and 97 (each is for a different NVDEC encoder...)'	n/a	n/a	n/a	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_17	GPU[0-7] NVJPEG Error	'No HW mechanism to inject a fatal fault in the video engines exist. We can force engine recovery via SW tests but it will not provie the same XID number although it will  test the same error handling code path for engine recovery. 

 No EINJ capability'	Arvind G		GPU [0-7] has experienced a failure in a JPEG decoding engine.	n/a			Mei Diao (3627626)		NA		Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: Warning, and Resolution of redfish event log to :

Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_18	GPU[0-7] NVDEC Error	No HW mechanism to inject a fatal fault in the video engines exist. We can force engine recovery via SW tests but it will not provie the same XID number although it will  test the same error handling code path for engine recovery. 	Arvind G		GPU [0-7] has experienced a failure in its video decoding engine.	n/a			Mei Diao (3627626)		NA		Restart application. If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: Warning, and Resolution of redfish event log to :

Restart application. If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_19	GPU[0-7] OFA Error	No HW mechanism to inject a fatal fault in the video engines exist. We can force engine recovery via SW tests but it will not provie the same XID number although it will  test the same error handling code path for engine recovery. No EINJ capability	Arvind G		GPU [0-7] Has experienced a failure in the Optical Flow Accelerator (OFA) hardware engine.	n/a			Mei Diao (3627626)		NA		Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: Warning, and Resolution of redfish event log to :

Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_20	GPU [0-7] Nvlink Error	Can Inject a small subset of nvlink errors with a HULK license. SRT exist for a smaller subset. And some in NVSWITCH gtest	Ivan Yee		GPU [0-7] Has experienced a failure on one nvlink connection to an nvswitch.	QS0			Ivan Yee				Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}/Ports/{PortId}

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} {NVLinkId}", "Error"]

Update Resolution of redfish event log to:
Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.

and AdditionalData:
{GPUId} {NVLinkId} replay error count
{GPUId} {NVLinkId} recovery error count
{GPUId} {NVLinkId} flit CRC error count
{GPUId} {NVLinkId} data CRC error count

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'	'4/26 Note:
Step 1: reset the GPU (try retraining the link)
(Not available via nvidia-smi) Step 2: reset the NVSwitch
Step 3: power cycle or reboot the server if step 1/2 does not help

4/26 Note:
Kun - can we report which link hsa fault? yes

5/3 Note: the {NVLinkId} will defer to QS0.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}/Ports/{PortId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} {NVLinkId}", "Error"]	'{GPUId} {NVLinkId} replay error count
{GPUId} {NVLinkId} recovery error count
{GPUId} {NVLinkId} flit CRC error count
{GPUId} {NVLinkId} data CRC error count'
GPU Failures	GPU_21	GPU [0-7] MMU Fault	Can be generated with a Cuda APP or an existing SRT test. 	Xiaofan Li/Mei Dao		GPU [0-7] Has experienced an illegal address fault from an application using the GPU.	QS0			Mei Diao   (3577546)		3058452		Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: OK, and Resolution of redfish event log to :

Restart application.  If the application continues to trigger the same event, investigate application changes and logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_22	GPU [0-7] SM Warp Exception	Needs CUDA app to generate SM WARP exceptions.	Mei Dao		GPU [0-7] Has experienced an instruction failure on an SM Warp.	QS0			Mei Diao   (3577546)	test case is ready, please review	3016720		Restart application.  If the application continues to trigger the same event, investigate application changes and application logs to investigate potential application problem.	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: OK, and Resolution of redfish event log to :

Restart application.  If the application continues to trigger the same event, investigate application changes and application logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_23	GPU [0-7] CUDA Channel Reset		Mei Dao		GPU [0-7] CUDA requests early reset of a channel after experiencing other errors.	QS			Mei Diao (3577546)	test case is ready, please review	3016721		'Restart application.  Review other Xids for indications of other hardware failures.
If the application continues to trigger the same event, investigate application changes and application logs to investigate potential application problem.'	'1. Create an XID redfish event log 
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]

2. Update Severity: OK, and Resolution of redfish event log to :

Restart application.  Review other Xids for indications of other hardware failures.
If the application continues to trigger the same event, investigate application changes and application logs to investigate potential application problem.'	'Likely application/software issue.

4/26 Note: 
HealthRollup not handled by HMC for app/sw issue.

HMC Behavior - HMC logs XID redfish event log'	n/a	n/a	n/a	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} DriverEventMessage", "(Xid: {Xid errno}) {Information about the Xid}"]	n/a
GPU Failures	GPU_24	GPU [0-7] Reset Required					QS							Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
Base.1.13.ResetRequired

and MessageArgs: 
["/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}", "ForceRestart"]

Update Resolution of redfish event log to:
Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.

and AdditionalData:


3. Create an XID event log. Accessible through:
n/a (no associated XID)'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	'In order to apply changes, recover from errors, or complete the operation, a component reset is required with the Reset action URI ''%1'' and ResetType ''%2''.'	Base.1.13.ResetRequired	Base	["/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}", "ForceRestart"]	
GPU Failures	GPU_25	GPU [0-7] Drain and Reset Recommended					QS							Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 

to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
Base.1.13.ResetRecommended

and MessageArgs: 
["/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}", "ForceRestart"]

Update Resolution of redfish event log to:
Reset the GPU or power cycle the BaseBoard.  If problem persists, isolate the server for RMA evaluation.

and AdditionalData:


3. Create an XID event log. Accessible through:
n/a (no associated XID)'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	'In order to recover from errors, a component reset is recommended with the Reset action URI ''%1'' and ResetType ''%2''.'	Base.1.13.ResetRecommended	Base	["/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}", "ForceRestart"]	
GPU Failures	GPU_26	GPU[0-7] Disabled single bit interrupts				GPU [0-7] has experienced a high rate of single bit corrrected memory errors.  Interrrupts are disabled to avoid further overheads.	QS							No recovery required	'1. Change HealthRollup for following URIs 
n/a 
n/a

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} Memory", "High SingleBit ECC Error Rate"]

Update Resolution of redfish event log to:
No recovery required

and AdditionalData:
{GPUId} Dynamic Page Retirement SBE errors
{GPUId} Dynamic Page Retirement DBE errors

3. Create an XID event log. Accessible through:
/redfish/v1/Chassis/{GPUId}LogServices/XID/Entries/{EntryId}'		n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} Memory", "High SingleBit ECC Error Rate"]	'{GPUId} Dynamic Page Retirement SBE errors
{GPUId} Dynamic Page Retirement DBE errors'
NVSwitch	NVSwitch_1	NVSwitch[0-3] fallen off of bus	Joseph Obedowski US to give injection steps	Joseph Obedowski US		A device falling off the PCIe bus usually indicates a catastrophic failure of the host interface.  This may be caused by a thermal alert, security event, or clock failure.	QS0			SWQA (Ivan Yee)				(Covered by different scenarios as listed below)	'HMC will report this error indirectly. This condition is derived from other errors below such as over temperature, PCIe link error, presence state change event, etc.
(Covered by different scenarios as listed below)'	'4/26 Note:
Detection
- Power state of NVSwich (from FPGA)
- PCIe link down, etc...

HMC to report "fallen off of bus"? No

HMC behavior - Derived conditions from PCIe link error, etc. '	n/a	n/a	n/a	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} DriverEventMessage", "(SXid: {SXid errno}) {Information about the SXid}"]	n/a
NVSwitch	NVSwitch_2	NVSwitch[0-3] Over Temp	Yes, in diagnostic debug tests (capable through FPGA DFV/DFT logic, please refer to FPGA page SR#6)	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	An over temperature event happens when external sensors detect the NVSwitch has reached a critical temperature and must be powered off immediately to prevent physical damage.	ES			System QA		3587955		Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId} 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters


and update Resolution of redfish event log to:
Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover.  

3. Create an SXID event log. Accessible through:
/redfish/v1/Chassis/{NVSwitchId}LogServices/SXID/Entries/{EntryId}'	'4/26 Note:
Will finalize in Thermal tab.'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
NVSwitch	NVSwitch_3	NVSwitch[0-3] Thermal warning	Yes, in diagnostic debug tests			'A thermal alert event happens when temperature sensors detect that a threshold has been crossed, and countermeasures are enabled.
Countermeasures reduce power consumption and will reduce throughput performance until the temperature sensors detect NVSwitch ioperating temperature is below the threshold.'	ES			System QA/MODs		3587955		Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId} 

to Severity: Warning, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters


and update Resolution of redfish event log to:
Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold.  

3. Create an SXID event log. Accessible through:
/redfish/v1/Chassis/{NVSwitchId}LogServices/SXID/Entries/{EntryId}'	'4/26 Note:
Will finalize in Thermal tab.'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
NVSwitch	NVSwitch_4	NVSwitch[0-3] VR failure	Capable through FPGA DFV/DFT logic, please refer to FPGA page SR#12	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'Drop off the bus?
NVLink: nvldl error'	ES			System QA				Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change


and update Resolution of redfish event log to:
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation. 

3. Create an SXID event log. Accessible through:
n/a (no associated SXID)'	4/26 Note: Will finalize in VR tab.	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PowerGood", "Abnormal Power Change"]	'{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change'
NVSwitch	NVSwitch_5	NVSwitch[0-3] I2C Hang	None			Only encountered while checking for Tdiode value (temperature)	QS			HW Validation				No recovery required.	'Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} I2C", "Hang"]

and AdditionalData:


Update Severity: OK, and Resolution of redfish event log to:
No recovery required.'	'4/26 Note:
Kun to check with Leon for I2C hang detection logic.- NEW for Vulcan

5/2: [Kun] from FPGA register table.'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} I2C", "Hang"]	
NVSwitch	NVSwitch_6	NVSwitch[0-3] SMBPBI server unavailable	John Harkins/Michael Y to suggest injection tool 	John Harkins/Michael Y/Shrikant Giridhar		TBD - does NSCQ report any errors (check with Tuan)	QS							TBD	TBD	'5/3 Note: 
Check with Shrikant any way to detect it. What will happen and how to recover?'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} SMBPBI", "Server Unavailable"]	
NVSwitch	NVSwitch_7	NVSwitch[0-3] PCIe link speed state	Joseph Obedowski US to suggest tool	Joseph Obedowski US		'Switch driver does not check for PCIe link speed state - i.e. check for degradation of link
HMC monitors PCIe link speeds for switch'	ES					3586773		Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PCIe", "Abnormal Speed Change"]

and AdditionalData:
{NVSwitchId} PCIe link speed


and update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation. 

3. Create an SXID event log. Accessible through:
n/a (no associated SXID)'	'4/26 Note:
Similar to GPU PCIe link speed change'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PCIe", "Abnormal Speed Change"]	{NVSwitchId} PCIe link speed
NVSwitch	NVSwitch_8	NVSwitch[0-3] PCIe link width state	Joseph Obedowski US to suggest tool	Joseph Obedowski US			ES					3586773		Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PCIe", "Abnormal Width Change"]

and AdditionalData:
{NVSwitchId} PCIe link width


and update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation. 

3. Create an SXID event log. Accessible through:
n/a (no associated SXID)'		'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PCIe", "Abnormal Width Change"]	{NVSwitchId} PCIe link width
NVSwitch	NVSwitch_9	NVSwitch[0-3] PCIe link error	Joseph Obedowski US to suggest too	Joseph Obedowski US		'TBD - need to check if AERs are handled by the switch driver
HMC - needs to check'	ES					3586773		Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PCIe", "{PCIe Uncorrectable Error}"]

and AdditionalData:
{NVSwitchId} PCIe non-fatal error counts
{NVSwitchId} PCIe fatal error counts


and update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation. 

3. Create an SXID event log. Accessible through:
/redfish/v1/Chassis/{NVSwitchId}LogServices/SXID/Entries/{EntryId}'		'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PCIe", "{PCIe Uncorrectable Error}"]	'{NVSwitchId} PCIe non-fatal error counts
{NVSwitchId} PCIe fatal error counts'
NVSwitch	NVSwitch_10	NVSwitch[0-3] Link training error	'Subset supported with NVSwitch gtest with HULK.
Check with April J if there are additional tests in MODs'	April J/MODs		'FM should note that links are not trained and flag errors; check whether NVLinks run in degraded mode or fail init

This is in-band and no SMBPBI telemetry available for link training errors'	QS			SWQA (Ivan Yee)				Restart Fabric Manager or power cycle the BaseBoard. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{SwitchId}/Ports/{PortId} 

to Severity: Critical, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} {NVLinkId}", "Training Error"]

and AdditionalData:
{NVSwitchId} {NVLinkId} Link training error count


and update Resolution of redfish event log to:
Restart Fabric Manager or power cycle the BaseBoard. If problem persists, isolate the server for RMA evaluation. 

3. Create an SXID event log. Accessible through:
/redfish/v1/Chassis/{NVSwitchId}LogServices/SXID/Entries/{EntryId}'	'No gracefully NVSwitch reset support currently. PCIe fundamentatl assert/deassert (Redfish reset actions) may cause PCIe surprse down - crush server (unexpected event) - check with Vishal

[Heinz] If a nvlink fails to train then power cycle and try again. An option might be to stop/start fabric manager.

5/3 Note:
Kun/Vishal - attached replays, recovery, and CRC errors in AddtionalDataURI? No
Kun - which link has fault?  Yes, defer to QS0.
Kun - OriginOfCondition on Port? Yes, defer to QS0.

'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{SwitchId}/Ports/{PortId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} {NVLinkId}", "Training Error"]	{NVSwitchId} {NVLinkId} Link training error count
NVSwitch	NVSwitch_11	NVSwitch[0-3] Successful link replays or recoveries	None	April J/MODs			QS			SWQA (Ivan Yee)				No recovery required.	'1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} {NVLinkId}", "Successful Replays"]
["{NVSwitchId} {NVLinkId}", "Successful Recoveries"]

and AdditionalData:
{NVSwitchId} {NVLinkId} replay rollover correctable error count


2. Update Severity: OK, and Resolution of redfish event log to:
No recovery required.'	'5/3 Note:
Metrics only? No. will log it.
Threshold (leaky-bucket)? TBD
HealthRollup? No, log only. Log under System log.
Severity: OK.

Do not implement Resolution property.
'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{SwitchId}/Ports/{PortId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	'["{NVSwitchId} {NVLinkId}", "Successful Replays"]
["{NVSwitchId} {NVLinkId}", "Successful Recoveries"]'	{NVSwitchId} {NVLinkId} replay rollover correctable error count
NVSwitch	NVSwitch_12	NVSwitch[0-3] Link CRC Errors	None	April J/MODs			QS			SWQA (Ivan Yee)				No recovery required.	'1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} {NVLinkId}", "Flit CRC Errors"]
["{NVSwitchId} {NVLinkId}", "Data CRC Errors"]

and AdditionalData:
{NVSwitchId} {NVLinkId} Link training error count


2. Update Severity: OK, and Resolution of redfish event log to:
No recovery required.'	'5/3 Note:
Metrics only? No. will log it.
Threshold (leaky-bucket)? TBD
HealthRollup? No, log only. Log under System log.
Severity: OK.

Do not implement Resolution property.
'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'	/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{SwitchId}/Ports/{PortId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	'["{NVSwitchId} {NVLinkId}", "Flit CRC Errors"]
["{NVSwitchId} {NVLinkId}", "Data CRC Errors"]'	'{GPUId} {NVLinkId} replay error count
{GPUId} {NVLinkId} recovery error count
{GPUId} {NVLinkId} flit CRC error count
{GPUId} {NVLinkId} data CRC error count'
NVSwitch	NVSwitch_13	NVSWITCH_ERR_HW_HOST	None	Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	'System level problems. IO/PRI failures indicate that host IO is reporting errors or sub-units are unresponsive.  Thermal warnings & errors occur when the chip''s temperature is approaching or has reached critical levels that will trigger an emergency shutdown.'	QS							'IO failures - This is a fatal error requiring chip reset.
Thermal - Check system cooling'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_14	NVSWITCH_ERR_HW_NPORT_INGRESS		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Incorrect configuration of the fabric.  ECC error in routing tables	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			'Check routing configuration of the topology
Single bit errors are self-correcting and non-fatal
Double bit errors are fatal, logged, and may indicate on-chip RAM degradation'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_15	NVSWITCH_ERR_HW_NPORT_EGRESS		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Data packet corruption.  Data packet tracking errors.  Timeout errors	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_16	NVSWITCH_ERR_HW_NPORT_TSTATE		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	State tracking corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_17	NVSWITCH_ERR_HW_NPORT_ROUTE		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Incorrect configuration of the fabric.  ECC error in distribution table	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_18	NVSWITCH_ERR_HW_NVLCTRL		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	NVLink data packet corruption (single or double bit errors)	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			'Check NVLink status and error counts
Check NVLink integrity'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_19	NVSWITCH_ERR_HW_NVLIPT		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	NVLink data packet corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			'Check NVLink status and error counts
Check NVLink integrity'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_20	NVSWITCH_ERR_HW_NVLTLC		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	NVLink data packet corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			'Check NVLink status and error counts
Check NVLink integrity'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_21	NVSWITCH_ERR_HW_DLPL		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	NVLink data packet corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			'Check NVLink status and error counts
Check NVLink integrity'	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_22	NVSWITCH_ERR_HW_MINION		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	MINION controller failure	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			Chip reset	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_23	NVSWITCH_ERR_HW_NXBAR		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Crossbar data corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm			Fatal error requiring chip reset	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_24	NVSWITCH_ERR_HW_NPORT_SOURCETRACK		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Data packet tracking errors (single or double bit errors)	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_25	NVSWITCH_ERR_HW_NVLIPT_LNK		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	NVLink error	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_26	NVSWITCH_ERR_HW_SOE		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	SOE controller failure	QS							Chip reset	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_27	NVSWITCH_ERR_HW_CCI		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Cable interconnect failure	QS							Check cable integrity	TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_28	NVSWITCH_ERR_HW_NPORT_MULTICASTTSTATE		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Multicast state tracking corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
NVSwitch	NVSwitch_29	NVSWITCH_ERR_HW_NPORT_REDUCTIONTSTATE		Gary	Wed Dec 08 2021 00:00:00 GMT-0800 (Pacific Standard Time)	Reduction state tracking corruption	ES	NVSwitch GTest			Regression testing to be enabled once LS10 added to DVS Farm				TBD	'4/28 Note:
New item and need further evaluation. Check with Vishal.'									
Thermal	Thermal_1	GPU[0-7] Over Temp	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#5	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s, GPU will shutdown autonomously.	ES			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.	'1. Change HealthRollup for following URIs 
System shutdown 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}
to Severity: /redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}, and update Conditions.

2. Create a redfish event log. Accessible through: 
/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}

with MessageId: 
The resource property %1 has exceeded error threshold of value %2.

and MessageArgs: 
["{GPUId} Temperature", "{UpperFatal Threshold}"]

Update Resolution of redfish event log to:
Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.

and AdditionalData:
{GPUId} Temperature
{GPUId} Thermal Parameters

3. Create an XID event log. Accessible through:
ResourceEvent.1.0.ResourceErrorThresholdExceeded'	'HAs access to same information. cant''t control system FAN speed directly

4/21 Note:
Amar suggested recovery steps - "System shutdown from host BMC".

4/22 Note: Collect thermal log? Not support historical info. (FDR)

4/28 Note:
MessageId/MessageArgs - Option 2 is preferred.
Option 1. ResourceEvent.1.0.ResourceErrorsDetected
"MessageArgs": ["{GPUId} Temperature", "Overheat"]
"Message": "The resource property %1 has detected errors of type ''%2''."

Option 2. ResourceErrorThresholdExceeded
"MessageArgs": ["{GPUId} Temperature", "{Threshold}"]
"Message": "The resource property %1 has exceeded error threshold of value %2.",

Collect thresholds - ask Margaret 

5/3 Note: 
Threshold will be included in Message/MessageArgs, available in QS0. 
AdditionalDataURI contains Temperature Reading and Thresholds.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{GPUId} Temperature", "{UpperFatal Threshold}"]	'{GPUId} Temperature
{GPUId} Thermal Parameters'
Thermal	Thermal_2	GPU Thermal Warning	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#21	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	GPU[0-7] has crossed warning temperature threshold. It is expected that BMC increase system FAN speed	QS			System QA		3587955	I2C2_ALERT_N	Increase the BaseBoard cooling and check thermal environmental to ensure the GPU operates under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}

to Severity: Warning, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{GPUId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{GPUId} Temperature
{GPUId} Thermal Parameters

and update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the GPU operates under UpperCritical threshold. '	'HAs access to same information. cant''t control system FAN speed directly'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Chassis/{GPUId}/Sensors/{GPUTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	'ResourceEvent
OpenBMC'	["{GPUId} Temperature", "{UpperCritical Threshold}"]	'{GPUId} Temperature
{GPUId} Thermal Parameters'
Thermal	Thermal_3	Retimer[0-3, 4-7] Over Temp	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#16	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	RET[0-7] has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s,	QS			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{RetimerTempId}

to Severity: Critical, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters

and update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'HAs access to same information. cant''t control system FAN speed directly'	/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{RetimerTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]	'{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters'
Thermal	Thermal_4	NVSwitch[0-3] Over Temp	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#6	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	NVSW[0-4] has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s,	QS			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}

to Severity: Critical, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters

and update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'HAs access to same information. cant''t control system FAN speed directly'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
Thermal	Thermal_5	NVSwitch[0-3] Thermal warning	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#22	Leon/Amanda	Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	NVSW[0-4] has crossed warning temperature threshold. It is expected that BMC increase system FAN speed	QS			System QA		3587955	I2C2_ALERT_N	Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}

to Severity: Warning, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters

and update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold. '	'HAs access to same information. cant''t control system FAN speed directly'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{NVSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
Thermal	Thermal_6	PCIe Switch Over Temp	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#7	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	REXSW has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s,	ES			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeSwitchTempId}

to Severity: Critical, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters

and update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'HAs access to same information. cant''t control system FAN speed directly'	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]	'{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters'
Thermal	Thermal_7	FPGA Over Temp	No since FPGA FW does not support it.			REXSW has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s,	QS			System QA		3587955	FPGA_THERM_OVERT_N	Power off the BaseBoard within 1 second. Check thermal environmental to ensure FPGA operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId}

to Severity: Critical, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{FPGAId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:


and update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second. Check thermal environmental to ensure FPGA operates under UpperFatal threshold and power cycle the BaseBoard to recover. '		/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{FPGAId} Temperature", "{UpperFatal Threshold}"]	
Thermal	Thermal_8	FPGA Thermal warning	No since FPGA FW does not support it yet.			NA	QS			System QA		3587955	NA	NA	NA	FPGA FW does not support it yet.	/redfish/v1/Systems/{ComputerSystemId}/Processors/{FPGAId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	ResourceEvent	["{FPGAId} Temperature", "{UpperCritical Threshold}"]	
Thermal	Thermal_9	HMC OVERT Temp	Capable through FPGA DFV/DFT logic. please refer to FPGA page SR#10	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	HMC has crossed critical temperature threshold. It is expected that BMC performs orderly shutdown within 1s,	QS			System QA		3587955	THERM_OVERT_N	Power off the BaseBoard within 1 second. Check thermal environmental to ensure HMC operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	No HMC Access.	'HAs access to same information. cant''t control system FAN speed directly'	/redfish/v1/Managers/{HMCId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{HMCTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{HMCId} Temperature", "{UpperFatal Threshold}"]	
Thermal	Thermal_10	BaseBoard PCB Thermal Warning	Capable through FPGA SMBPBI. please refer to FPGA page SR#27	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Set temperature threshold have been crossed. Increase fan speed	ES			System QA		3587955	I2C2_ALERT_N	Increase the BaseBoard cooling and check thermal environmental to ensure the PCB Temperature reading is under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCBTempId}

to Severity: Warning, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{PCBTempId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{PCBTempId} Temperature
{PCBTempId} Thermal Parameters

and update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the PCB Temperature reading is under UpperCritical threshold. '	'HAs access to same information. cant''t control system FAN speed directly'	/redfish/v1/Chassis/{BaseboardId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCBTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	ResourceEvent	["{PCBTempId} Temperature", "{UpperCritical Threshold}"]	'{PCBTempId} Temperature
{PCBTempId} Thermal Parameters'
Thermal	Thermal_11	Inlet Thermal Warning	Capable through FPGA SMBPBI. please refer to FPGA page SR#25	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Set temperature threshold have been crossed. Increse fan speed	ES			System QA		3587955	I2C2_ALERT_N	Increase the BaseBoard cooling and check thermal environmental to ensure Inlet Temperature reading is under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{InletTempId}

to Severity: Warning, and update Conditions.

2. Create Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{InletTempId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{InletTempId} Temperature
{InletTempId} Thermal Parameters

and update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure Inlet Temperature reading is under UpperCritical threshold. '	'HAs access to same information. cant''t control system FAN speed directly'	/redfish/v1/Chassis/{BaseboardId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{InletTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	ResourceEvent	["{InletTempId} Temperature", "{UpperCritical Threshold}"]	'{InletTempId} Temperature
{InletTempId} Thermal Parameters'
HMC	HMC_1	HMC OVERT Temp	FPGA DFT	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	HMC has crossed critical temperature threshold. 	QS			System QA		3581141	THERM_OVERT_N	Power off the BaseBoard within 1 second. Check thermal environmental to ensure HMC operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	No HMC Access.	log only	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{HMCId} Temperature", "{UpperFatal Threshold}"]	
HMC	HMC_2	HMC unavailable	(All cases below)	Mahendra Y	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	HMC may be unavailable due to watchdog kick off or Redfish hang.	ES			System QA		3581141	n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	(Different scenarios as listed below)										
HMC	HMC_3	HMC Redfish service not available	'Cases:
- Make redfish service not to start at bootup.
- Stop the redfish service once its been up and running fine.
- Make redish server stop and does not restart after its been up and running fine.'	Mahendra Y	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'BMC can''t get any response from HMC Redfish service, and if HMC still working'	ES			System QA		3581141	n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'If HMC still working, HMC will create redfish event log and restart the Redfish service. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HMCId} Redfish", "Service Unavailable"]

and AdditionalData:



Update Severity: Critical, and Resolution of redfish event log to:
Power cycle the baseboard.'	'If HMC still working, HMC will log this event for HostBMC to query, and restart the Redfish service.
Otherwise, HMC can''t detect or log this failure by itself. Requires HostBMC to detect and log.'	n/a	n/a	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HMCId} Redfish", "Service Unavailable"]	
HMC	HMC_4	HMC USB network not accessible	'Cases: 
- Change the configuration to make sure USB0 net interface does not get any IP address
- Bringdown the USB0 interface using if commands 
- Modify the BMC configuration to not have usb1 network interface '	Mahendra Y	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	HMC USBnet not working	ES			System QA		3581141	n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'If HMC still working, HMC will log this event for HostBMC to query next time USB network is up, and restart the USB network service.
Otherwise, HMC can''t detect or log this failure by itself. Requires HostBMC to detect and log.'										
HMC	HMC_5	HMC USB connection not available	'Cases:
- Remove the USB gadget interface (change dtb)
- Start HMC and BMC without the usb cable 
- Remove the USB cable beteen HMC and BMC at run time '	Mahendra Y	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'BMC can''t see HMC as a USB endpoint'	ES			System QA		3581141	n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'If HMC still working, HMC will log this event for HostBMC to query next time USB connection is up, and reset the USB endpoint.
Otherwise, HMC can''t detect or log this failure by itself. Requires HostBMC to detect and log.'										
HMC	HMC_6	HMC not ready	Shutdow/restart HMC 	Mahendra Y	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	HMC is not ready and BMC see HMC_READY pin inactive	ES			System QA		3581141	n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'HMC can''t detect or log this failure by itself. Requires HostBMC to detect and log.'										
HMC	HMC_7	HMC SMBPBI Fencing state change	Take SMBPBI access privilege from Host BMC on i2c2 - opcode 0xA3	Mahendra Y	Thu Sep 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	FPGA enables SMBPBI fencing for HMC on both i2c and pcie interface leading to SMBPBI failures on HMC	QS						n/a	Controlled by Host BMC or a power cycle of baseboard would re-enable SMBPBI access privilege to HMC	'HMC will log the Fencing state as an event, SMBPBI telemetry will turn stale and SMBPBI dependent services - AML, Self Test will stop working.

A redfish event log will be created and accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HMCId} SMBPBI", "Fencing Privilege Disabled"]

Update Severity: Warning, and Resolution of redfish event log to:
Relinquish the fencing from Host BMC or Power cycle the baseboard.'	[Shakeeb] HMC will log the Fencing state as an event, SMBPBI telemetry will turn stale and SMBPBI dependent services - AML, Self Test will stop working			/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning		ResourceEvent.1.0.ResourceErrorsDetected		["{HMCId} SMBPBI", "Fencing Privilege Disabled"]	
HMC	HMC_8	HMC SMBPBI Failover to Redundant Interface				Failover of SMBPBI interface from pcie to i2c due to errors	ES						n/a	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'HMC will log the SMBPBI interface failover as an event, since SMBPBI is running on slower i2c interface, telemetry may turn stale.

A redfish event log will be created and accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HMCId} SMBPBI", "Failover to Redundant Interface(i2c)"]

Update Severity: Critical, and Resolution of redfish event log to:
Power cycle the baseboard.'				/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical		ResourceEvent.1.0.ResourceErrorsDetected		["{HMCId} SMBPBI", "Failover to Redundant Interface(i2c)"]	
PCIe SW	PEXSW_1	PCIe Switch PCIe link Error	'1.Microchip:  Microchip switch has a "Pattern Generator and Monitor" feature that can be utilized to inject patterns or errors on to Tx lanes.
2. Generate Bad DLLP'	Joseph O/Al Key		A PCIe link was established and had some error	QS							Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PCIe", "{PCIe Uncorrectable Error}"]

and AdditionalData:
{PCIeSwitchId} PCIe non-fatal error counts
{PCIeSwitchId} PCIe fatal error counts


Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.'		'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PCIe", "{PCIe Uncorrectable Error}"]	'{PCIeSwitchId} PCIe non-fatal error counts
{PCIeSwitchId} PCIe fatal error counts'
PCIe SW	PEXSW_2	PCIe Switch PCIe link Goes down	This can be tested using an error injection type interpose (like the Quarch test module) on a benchtop.  Alternatively we may want to look at an FPGA feature that would let us selectively reset devices on Vulcan.	Joseph O		A PCIe link was established and had some error causing link to be dropped	QS			 				No immediate recovery required. If this event occurs multiple times in a short period, check other PCIe error status for further diagnostics.	'1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PCIe", "LTSSM Link Down"]

and AdditionalData:
{PCIeSwitchId} PCIe link status


2. Update Resolution of redfish event log to:
No immediate recovery required. If this event occurs multiple times in a short period, check other PCIe error status for further diagnostics.'	'4/28 Note:
PCIe AER status notification has link down error.
Kun - Is it also reported incorrect speed change?

5/2 [Kun] this is a state change, not necessarily caused by any failure. So if see this event multiple times in a short period, need to check other PCIe error status for further diagnostics.'	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PCIe", "LTSSM Link Down"]	{PCIeSwitchId} PCIe link status
PCIe SW	PEXSW_3	PCIe Switch Over Temp	Capable through FPGA DFV/DFT logic. Please refer to FPGA page SR#7	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Temperature sensor connected to switch goes over the temperature threshold and issues alert	QS			System QA		3587955	FPGA asserts MIDP_OVERT	Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters


Update Resolution of redfish event log to:
Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. '		'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeSwitchTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]	'{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters'
PCIe SW	PEXSW_4	PCIe AER status notification	'This fault I guess depends on the port we''re using.  For downstream ports, I would expect the error propagate up from a downstream device and potentially result in a DPC event.
For upstream port, we would likely need to make use of the capabilities of the device upstream.  For the Microchip switch, when it''s plugged into a Viking, we could use the CX7 for this.  CX7 has error injection capabilities, however they don''t currenlty publish a tool to make use of them, we''ll need to get this.'	Joseph O		The configuration status space of each device contains AER settings. This can be observed to determine status.	QS							No recovery required.	'1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
The resource property %1 has detected errors of type %2.

and MessageArgs: 
["{PCIeSwitchId} PCIe", "{PCIe AER Notification}"]

and AdditionalData:
{PCIeSwitchId} PCIe non-fatal error counts
{PCIeSwitchId} PCIe fatal error counts


2. Update Severity: OK, and Resolution of redfish event log to :

No recovery required.'	'4/28 Note:
Correctable and uncorrectable AER register error 

No recovery for AER notification
Severity? No 
Resolution? No Recovery'	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	OK	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PCIe", "{PCIe AER Notification}"]	'{PCIeSwitchId} PCIe non-fatal error counts
{PCIeSwitchId} PCIe fatal error counts'
PCIe SW	PEXSW_5	Incorrect link width	Is there some GPU DFx setting where we can keep Link capability at x16 but only allow a subset of those lanes to work?  need to investigate.	Joseph O		Link through the retimer is not able to negotiate correct settings	QS							Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PCIe", "Abnormal Width Change"]

and AdditionalData:
{PCIeSwitchId} PCIe link width


Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.'		'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PCIe", "Abnormal Width Change"]	{PCIeSwitchId} PCIe link width
PCIe SW	PEXSW_6	Incorrect link speed	I expect we could just set the downstream port above the retimers to link at a lower speed.  That should show it as being in the degraded state.	Jimmy Huang TW		Link through the retimer is not able to negotiate correct settings	QS							Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PCIe", "Abnormal Speed Change"]

and AdditionalData:
{PCIeSwitchId} PCIe link speed
{PCIeSwitchId} PCIe requested link speed


Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.'		'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PCIe", "Abnormal Speed Change"]	'{PCIeSwitchId} PCIe link speed
{PCIeSwitchId} PCIe requested link speed'
FPGA	FPGA_1	FPGA Temp Alert (FPGA_LM95233_0_TEMP_CRIT(1))	Capable through DFT/DFV	 	Mon May 23 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle FPGA_LM95233_0_TEMP_CRIT(1) pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. Reg table will show error info at SENSOR_TEMP_WARN_INT/GPIO_OUTPUT1
4. SMBPBI will not capability of clearing FPGA temperature alert  https://nvbugs/3566536'	QS	PASS with FPGA FW v1.55		Kent Wang & System QA		https://nvbugs/3653874		Power off the BaseBoard within 1 second. Check thermal environmental to ensure FPGA operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{FPGAId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{FPGAId} Temperature
{FPGAId} Thermal Parameter


Update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second. Check thermal environmental to ensure FPGA operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'4/25 Note:
Recovery - "Host BMC should disable standby power immediatly. Check thermal environmental to ensure FPGA operates under UpperFatal threshold (125 degree C) and power cycle the BaseBoard to recover."

125 - UpperFatal threshold

Will finalize in Thermal tab.'	/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{FPGAId} Temperature", "{UpperFatal Threshold}"]	'{FPGAId} Temperature
{FPGAId} Thermal Parameter'
FPGA	FPGA_2	FPGA - BMC PCIe Error	No capability since FPGA/BMC design team could not offer the methods to triger the casesï¼ˆbug 35556953)			'Several events can cause this error: 1) The PCIE Gen2x1 link between FPGA and BMC is down, resulting FPGA missing from the PCIe enumeration; 2) BMC is filling up the FPGA''s internal buffer, causing the buffer to be full and unable to process further commands and therefore an I2C2_ALERT_N GPIO is triggered;  3) Transport layer packets corruption, and therfore an I2C2_ALERT_N GPIO is triggered; 4) FPGA''s process times out, and therfore an I2C2_ALERT_N GPIO is triggered;'	QS							Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
n/a (no dependent condition) 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{FPGAId} PCIe", "BMC {PCIe Uncorrectable Error}"]

and AdditionalData:
{FPGAId} BMC PCIe non-fatal error counts
{FPGAId} BMC PCIe fatal error counts


Update Resolution of redfish event log to: 
Reset the link. If problem persists, isolate the server for RMA evaluation.'	'4/25 Note:
Correctable error? No
Uncorrectable error? Yes
'	/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} PCIe", "BMC {PCIe Uncorrectable Error}"]	'{FPGAId} BMC PCIe non-fatal error counts
{FPGAId} BMC PCIe fatal error counts'
FPGA	FPGA_3	FPGA - HMC PCIe Error	No capability since FPGA/BMC design team could not offer the methods to triger the casesï¼ˆbug 35556953)			'Several events can cause this error: 1) The PCIE Gen2x1 link between FPGA and HMC is down, resulting FPGA missing from the PCIe enumeration; 2) HMC is filling up the FPGA''s internal buffer, causing the buffer to be full and unable to process further commands and therefore an I2C4_ALERT_N GPIO is triggered;  3) Transport layer packets corruption, and therfore an I2C4_ALERT_N GPIO is triggered; 4) FPGA''s process times out, and therfore an I2C4_ALERT_N GPIO is triggered;'	QS							Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
n/a (no dependent condition) 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{FPGAId} PCIe", "HMC {PCIe Uncorrectable Error}"]

and AdditionalData:
{FPGAId} HMC PCIe non-fatal error counts
{FPGAId} HMC PCIe fatal error counts


Update Resolution of redfish event log to: 
Reset the link. If problem persists, isolate the server for RMA evaluation.'	'4/25 Note:
Correctable error? No
Uncorrectable error? Yes
'	/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} PCIe", "HMC {PCIe Uncorrectable Error}"]	'{FPGAId} HMC PCIe non-fatal error counts
{FPGAId} HMC PCIe fatal error counts'
FPGA	FPGA_4	FPGA Thermal warning	No capability since FPGA FW has not supported yet. File Bug 3566536 for the FPGA FW support			N/A. it is not a critical fault, and FPGA has not decided whether to deploy Thermal warming for the FPGA. There is no alerts associated with FPGA thermal warning right now.	n/a							N/A	N/A	'4/25 Note:
Will finalize in Thermal tab.'	/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{FPGATempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{FPGAId} Temp", "Warning"]	
FPGA	FPGA_5	GPU OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle GPU OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related GPU reset would assert and PWR_EN would deassert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3592884		Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Chassis/{GPUId}/Sensors/{TempId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{GPUId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{GPUId} Temperature
{GPUId} Thermal Parameters


Update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, and GPU will shutdown autonomously. Check thermal environmental to ensure the GPU operates under UpperFatal threshold and power cycle the Baseboard to recover.'	'4/25 Note: Recovery to add "AC cycle the BaseBoard"

Will finalize in Thermal tab.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Chassis/{GPUId}/Sensors/{TempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{GPUId} Temperature", "{UpperFatal Threshold}"]	'{GPUId} Temperature
{GPUId} Thermal Parameters'
FPGA	FPGA_6	NVSW OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle NVSW OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related NVSW reset would assert, DVDD_EN/VDD_EN would deassert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3593539		Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{TempId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters


Update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, the NVSwitch will be held in reset. Check thermal environmental to ensure the NVSwitch operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'4/25 Note: Recovery to add "AC cycle the BaseBoard"

Will finalize in Thermal tab.'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{TempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperFatal Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
FPGA	FPGA_7	PEXSW OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle PEXSW OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related PEXSW reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3593541		Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
 /redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters

Update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, the PCIe Switch will be held in reset. Check thermal environmental to ensure the PCIe Switch operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'4/25 Note: Recovery to add "AC cycle the BaseBoard"

Will finalize in Thermal tab.'	'/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeSwitchTempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeSwitchId} Temperature", "{UpperFatal Threshold}"]	'{PCIeSwitchId} Temperature
{PCIeSwitchId} Thermal Parameters'
FPGA	FPGA_8	Retimer OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle Retimer OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related Retimer reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3593543		Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeRetimerTempId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters


Update Resolution of redfish event log to: 
Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. '	'4/25 Note: Recovery to add "AC cycle the BaseBoard"

Will finalize in Thermal tab.'	/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{PCIeRetimerTempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]	'{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters'
FPGA	FPGA_9	CAR_COME OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle CARC_COME OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3593545		TBD	TBD	'4/25 Note: 
- Multi-node TBD
- Recovery to add "AC cycle the BaseBoard"'									
FPGA	FPGA_10	HMC_OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle HMC OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	'PASS with FPGA FW v1.44 for HMC
Failed on FPGA FW v1.43 for HMC'		Rhys Hou & System QA		 https://nvbugs/3593553		Power off the BaseBoard within 1 second. Check thermal environmental to ensure HMC operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'HMC can''t detect or log this failure by itself. Requires HostBMC to detect and log.'	'4/25 Note: Recovery to add "AC cycle the BaseBoard"

Vishal to ask HMC resilency team

Will finalize in Thermal tab.'									
FPGA	FPGA_11	Alert caused by GPU PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle GPU PWR_GD pins
2. I2C1 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related GPU reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3608230		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerComputerSystemId}/Processors/{GPUId} 
 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{GPUId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{GPUId} Power Status


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/25 Note: Power cycle the BaseBoard.
Same as VR tab.'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerComputerSystemId}/Processors/{GPUId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{GPUId} PowerGood", "Abnormal Power Change"]	{GPUId} Power Status
FPGA	FPGA_12	Alert caused by NVSW PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle NVSW PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related NVSW reset would assert'	QS	'PASS with FPGA FW v1.60
FAIL with FPGA FW v1.43'		Rhys Hou & System QA		https://nvbugs/3609327		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId} 
 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{NVSwitchId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/25 Note: Power cycle the BaseBoard.
Same as VR tab.'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{NVSwitchId} PowerGood", "Abnormal Power Change"]	'{NVSwitchId} VDD Abnormal change
{NVSwitchId} DVDD Abnormal change
{NVSwitchId} HVDD Abnormal change
{NVSwitchId} 1V8 Abnormal change
{NVSwitchId} 3V3 Abnormal change
{NVSwitchId} 5V Abnormal change
{NVSwitchId} IBC Abnormal change'
FPGA	FPGA_13	Alert caused by HSC PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle HSC PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	'PASS with FPGA FW v1.60
FAIL with FPGA FW v1.43'		Rhys Hou & System QA		https://nvbugs/3609347		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD) 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HSCId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{HSCId} detailed alert status


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/27 Note
HSC0-9 - (NVSwitch/GPU) try to power cycle, if problem persists, need RMA

HSC10 - (HERM) Not in current scope and need further evaluation. Check with Vishal.

HSC11 - FPGA VR fault, need RMA'	'For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}'	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HSCId} PowerGood", "Abnormal Power Change"]	{HSCId} detailed alert status
FPGA	FPGA_14	Alert caused by SYS_VR PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle SYS_VR PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609357		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{SysVRId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
SysVR 3V3 Abnormal change
SysVR 1V8 Abnormal change


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/27 Note:
Same as VR tab'	/redfish/v1/Chassis/{BaseboardId}	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{SysVRId} PowerGood", "Abnormal Power Change"]	'SysVR 3V3 Abnormal change
SysVR 1V8 Abnormal change'
FPGA	FPGA_15	Alert caused by PEXSW PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle PEX_SW PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. PEXSW reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609363		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId} 
/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD) 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeSwitchId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{PCIeSwitchId} 0V8 Abnormal change


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/27 Note:
Same as VR tab'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{PCIeSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeSwitchId}'	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeSwitchId} PowerGood", "Abnormal Power Change"]	{PCIeSwitchId} 0V8 Abnormal change
FPGA	FPGA_16	Alert caused by Retimer PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle retimer PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. retimer reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609410		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 
 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{RetimerId} PowerGood", "Abnormal Power Change"]

and AdditionalData:
{RetimerId} 0V9 Abnormal change
{RetimerId} 1V8 VDD Abnormal change
{RetimerId} 1V8 LDO Abnormal change


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/27 Note:
Same as VR tab'	'/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}'		/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{RetimerId} PowerGood", "Abnormal Power Change"]	'{RetimerId} 0V9 Abnormal change
{RetimerId} 1V8 VDD Abnormal change
{RetimerId} 1V8 LDO Abnormal change
'
FPGA	FPGA_17	Alert caused by HMC PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle HMC PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609426		'It can be detected by HMC_PG not asserted (from FPGA).

Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	No HMC access.	'Kun suggested power cycle on the next maintainance window? if problem persists, need RMA

Same as VR tab.'									n/a
FPGA	FPGA_18	Alert caused by HERM/CAR PWR_GD state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle HERM/CAR PWR_GD pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609449		TBD	TBD	Not in current scope and need further evaluation. Check with Vishal.									n/a
FPGA	FPGA_19	Alert caused by GPU PRSNT state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle GPU PRSNT pins
2. I2C1 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related GPU reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3608397		Cordon the HGX server node for further diagnosis.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId} 
n/a (no dependent condition) 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.1.ResourceStateChanged

and MessageArgs: 
["{GPUId}", "Absent"]

and AdditionalData:



Update Resolution of redfish event log to: 
Cordon the HGX server node for further diagnosis.'		'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The state of resource `%1` has changed to %2.	ResourceEvent.1.1.ResourceStateChanged	ResourceEvent	["{GPUId}", "Absent"]	
FPGA	FPGA_20	Alert caused by NVSW PRSNT state run time change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle NVSW PRSNT pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related NVSW reset would assert'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3608760		Cordon the HGX server node for further diagnosis.	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId} 
n/a (no dependent condition) 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.1.ResourceStateChanged

and MessageArgs: 
["{NVSwitchId}", "Absent"]

and AdditionalData:



Update Resolution of redfish event log to: 
Cordon the HGX server node for further diagnosis.'	4/27 Note: Same as GPU. One of the cases cause NVSwitch fallen off of bus.	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId}'	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The state of resource `%1` has changed to %2.	ResourceEvent.1.1.ResourceStateChanged	ResourceEvent	["{NVSwitchId}", "Absent"]	
FPGA	FPGA_21	Alert caused by GPU thermal alert	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle GPU thermal alert pins
2. I2C1 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3608424		Increase the BaseBoard cooling and check thermal environmental to ensure the GPU operates under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId} 
/redfish/v1/Chassis/{GPUId}/Sensors/{TempId} 

to Severity: Warning, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{GPUId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{GPUId} Temperature
{GPUId} Thermal Parameters


Update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the GPU operates under UpperCritical threshold. '	'4/27 Note:
Will finalize in thermal tab'	'/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}'	/redfish/v1/Chassis/{GPUId}/Sensors/{TempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	'ResourceEvent
OpenBMC'	["{GPUId} Temperature", "{UpperCritical Threshold}"]	'{GPUId} Temperature
{GPUId} Thermal Parameters'
FPGA	FPGA_22	Alert caused by NVSW thermal alert	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle NVSW thermal alert pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3608471		Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId} 
/redfish/v1/Chassis/{NVSwitchId}/Sensors/{TempId} 

to Severity: Warning, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters


Update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the NVSwitch operates under UpperCritical threshold. '	'4/27 Note:
Will finalize in thermal tab'	'/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{FabricId}/Switches/{NVSwitchId}'	/redfish/v1/Chassis/{NVSwitchId}/Sensors/{TempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	'ResourceEvent
OpenBMC'	["{NVSwitchId} Temperature", "{UpperCritical Threshold}"]	'{NVSwitchId} Temperature
{NVSwitchId} Thermal Parameters'
FPGA	FPGA_23	HERM_OVERT alert	Capable through DFT/DFV		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle HERM OVERT pins
2. OVERT pin could assert to notify BMC and SMBPBI could return correct interrupt source'	QS	PASS with FPGA FW v1.43 for HERMES		Rhys Hou & System QA		https://nvbugs/3593551		TBD	TBD	'4/27 Note:
Not in current scope and need further evaluation. Check with Vishal.'									
FPGA	FPGA_24	Alert caused by EROT FATAL pin state change	Capable through DFT/DFV		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Use DFT/DFV logic to toggle EROT FATAL pins
2. I2C1 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
'	QS	PASS with FPGA FW v1.43		Rhys Hou & System QA		https://nvbugs/3609546		talk to glacier directly via PLDM vendor command to triage	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{ERoTId} 
n/a (no dependent condition) 

to Severity: Crtical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{ERoTId} ERoT_Fatal", "Abnormal State Change"]

and AdditionalData:



Update Resolution of redfish event log to: 
talk to glacier directly via PLDM vendor command to triage'	'5/3 Note:
Kun - check with Terry how to differentiate ERoT recovery vs ERoT_Fatal. How to recover from both of the scenarios?

MessageArgs:
["{ERoT_APId} ERoT_Fatal", "Abnormal State Change"]'	/redfish/v1/Chassis/{ERoTId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Crtical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{ERoTId} ERoT_Fatal", "Abnormal State Change"]	
FPGA	FPGA_25	Alert caused by Inlet sensor temperture alert	Capable through i2ctools		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. use SMBPBI to decrease inlet sensor alert threshold
2. I2C2 alert pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. After change inlet sensor alert threshold back to default and send SMBPBI to clean the interrupt, I2C2 alert pin should deassert.'	QS	PASS with FPGA FW v1.42		Kent Wang & System QA		https://nvbugs/3586278		Increase the BaseBoard cooling and check thermal environmental to ensure Inlet Temperature reading is under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}/ThermalSubsystem 
/redfish/v1/Chassis/{BaseboardId}/Sensors/{InletTempId} 

to Severity: Warning, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{InletTempId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{InletTempId} Temperature
{InletTempId} Thermal Parameters


Update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure Inlet Temperature reading is under UpperCritical threshold. '	'4/27 Note:
Will finalize in thermal tab'	/redfish/v1/Chassis/{BaseboardId}/ThermalSubsystem	/redfish/v1/Chassis/{BaseboardId}/Sensors/{InletTempId}	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	ResourceEvent	["{InletTempId} Temperature", "{UpperCritical Threshold}"]	'{InletTempId} Temperature
{InletTempId} Thermal Parameters'
FPGA	FPGA_26	Alert caused by HSC alert	Capable through i2ctools		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. use i2c to decrease HSC temperature alert threshold
2. I2C2 alert pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. After change inlet sensor alert threshold back to default and send SMBPBI to clean the interrupt, I2C2 alert pin should deassert.'	QS	PASS with FPGA FW v1.42		Kent Wang & System QA		https://nvbugs/3590672		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId} 
/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD) 

to Severity: Warning or Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{HSCId} Alert", "{HSC Alert Info}"]

and AdditionalData:
{HSCId} detailed alert status


Update Resolution of redfish event log to: 
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'Warning or Critical?

{HSC Alert Info}
- "Communication fault" - Warning? for management
- "Temperature fault or warning"
- "VIN under voltage"
- "MOSFET is not switched on"
- "Circuit breaker fault"
- "PET is shorted"
- "Input voltage or current fault"
- "Output voltage fault or warning"

5/3 Note: defer to QS0'	'For HSC[0-7]:
/redfish/v1/Chassis/{GPUId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{GPUId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{GPUId}

For HSC[8-9]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Chassis/{NVSwitchId}
/redfish/v1/Chassis/{BaseboardId}/PCIeDevices/{NVSwitchId}
/redfish/v1/Fabrics/{NVLinkFabricId}/Switches/{NVSwitchId}

For HSC[11]:
/redfish/v1/Chassis/{BaseboardId}
/redfish/v1/Systems/{ComputerComputerSystemId}/Processors/{FPGAId}'	/redfish/v1/Chassis/{BaseboardId}/PowerSubsystem/PowerSupplies/{PowerSupplyId} (TBD)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning or Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{HSCId} Alert", "{HSC Alert Info}"]	{HSCId} detailed alert status
FPGA	FPGA_27	Alert caused by PCB sensor temperature alert	Capable through i2ctools		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. use SMBPBI to decrease pcb sensor alert threshold
2. I2C2 alert pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. After change inlet sensor alert threshold back to default and send SMBPBI to clean the interrupt, I2C2 alert pin should deassert.'	QS	PASS with FPGA FW v1.42		Kent Wang & System QA		https://nvbugs/3587129		Increase the BaseBoard cooling and check thermal environmental to ensure the PCB Temperature reading is under UpperCritical threshold. 	'1. Change HealthRollup for following URIs 
/redfish/v1/Chassis/{BaseboardId}/ThermalSubsystem 
n/a (no dependent condition) 

to Severity: Warning, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceWaringThresholdExceeded

and MessageArgs: 
["{PCBTempId} Temperature", "{UpperCritical Threshold}"]

and AdditionalData:
{PCBTempId} Temperature
{PCBTempId} Thermal Parameters


Update Resolution of redfish event log to: 
Increase the BaseBoard cooling and check thermal environmental to ensure the PCB Temperature reading is under UpperCritical threshold. '	'4/27 Note:
Will finalize in thermal tab'	/redfish/v1/Chassis/{BaseboardId}/ThermalSubsystem	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Warning	The resource property %1 has exceeded its warning threshold of value %2."	ResourceEvent.1.0.ResourceWaringThresholdExceeded	ResourceEvent	["{PCBTempId} Temperature", "{UpperCritical Threshold}"]	'{PCBTempId} Temperature
{PCBTempId} Thermal Parameters'
FPGA	FPGA_28	Other Alerts from devices handle	Capable through DFT/DFV			'I2Cx_PERI_ERROR/HSIO_BACKEND_N_ERROR/SMBPBI_FATAL_ERROR
EROT SPI Error'	QS	'Need more discussion for I2Cx_PERI_ERROR
Need FPGA FW support for MCTP/MCTP error error injection'		Rhys Hou & System QA				'Communication Alerts can be triaged via SMBPBI interrupts opcode as well as the register table dump. Communication Alerts would not cause any in-band failures. Re-attempt the same command to see if alert persists. If the alerts persist and the device is pex switch or retimer, Users can attempt reset the pex switch or retimer or DC cycle the board to try to recover. If these method doesn''t work,  The physical interface or the target device is not functional. Vishal/Heniz to see if we need RMA on this. '	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_29	GPU wrong PEC byte hanlde in SMBBPI	Capable only on emulation platform				QS	'Validate SMBPBI over I2C handle for GPU wrong PEC byte on emulation platform through forcing GPU PEC byte as 0 by emulation controller and FPGA would return byte count as 0xFF.
For SMBPBI over PCIE handle for GPU wrong PEC byte, wait for stable gputool to verify'		Rhys Hou & System QA				'Try the same command again to see if PEC failure persists. If so, the i2c interface is not functional or GPU device SMBPBI server is not functional.    Users can attempt reset the GPU or DC cycle the board to try to recover. If these method doesn''t work, Vishal/Heniz to see if we need RMA on this.  Vishal/Heniz to see if we need RMA on this. '	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_30	FPGA SMBPBI timeout handle	Capable through DFT/DFV		Move to 2022/05/13 due to Scout FPGA validation test requested by Peter(Original schedule 2022/04/29)	'1. force related downstream I2C SCL to low and send SMBPBI traffic which requires traffic on this downstream I2C bus to trigger timeout, check the I2C2/4 alert is triggered and SMBPBI indicates it is timeout error causing the alert.
2. SMBPBI/I2C request for other downstream I2C buses should not be affected.
3. release related downstream I2C SCL and clear the alert triggered by SMBPBI timeout send I2c traffic which requires traffic on this downstream I2C bus should be successful again.'	QS	Fail about error status. 		Rhys Hou & System QA		https://nvbugs/3646211		If timeout persistently happens, either FPGA has bug or the interface is not functional. Live debug session would be needed with the customer. 	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_31	FPGA I2C timeout handle	Capable through DFT/DFV		Move to 2022/05/20 due to Scout FPGA validation test requested by Peter(Original schedule 2022/04/29)	'1. force related downstream I2C SCL to low and send I2C traffic which requires traffic on this downstream I2C bus to trigger timeout
2. SMBPBI/I2C request for other downstream I2C buses should not be affected.
3. release related downstream I2C SCL and send SMBPBI traffic which requires traffic on this downstream I2C bus should be successful again.'	QS	Fail about error status. 		Rhys Hou & System QA		https://nvbugs/3646211		If timeout persistently happens, either FPGA has bug or the interface is not functional. Live debug session would be needed with the customer. 	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_32	Clock buffer hardcode handle for GPU/NVSW PWR_GD state changes	Capable through DFT/DFV		Move to 2022/05/25 due to Scout FPGA validation test requested by Peter(Original schedule 2022/04/29) and lack of system for validation	'1. force several GPU/NVSW PWR_GD state to low
2. check whether related clock buffer output fulfills the expectation
3. release GPU/NVSW PWR_GD state back to normal
4. check clock output buffer output changes back to default'	QS	Fail with v1.58		Rhys Hou & System QA		https://nvbugs/3692003		'If the feature doesn''t work, it is a FPGA bug. Provide FPGA team with the register dump and FPGA team would need to provide fix. '	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_33	Clock buffer access while hardcode is in process	Capable through DFT/DFV		Move to 2022/06/03 due to Scout FPGA validation test requested by Peter(Original schedule 2022/05/13)	'1. continuously generate pulse on GPU/NVSW PWR_GD to make clock buffer hardcode module execute periodically
2. send SMBPBI request to get clock buffer output state in parallel with step#1'	QS	PASS with v1.56		Rhys Hou & System QA				'If the feature doesn''t work, it is a FPGA bug. Provide FPGA team with the register dump and FPGA team would need to provide fix. '	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_34	Run DC power cycles with PG_* signals held low.	Capable through DFT/DFV		Fri Apr 22 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. force several PG signals to low
2. override BASE_PWR_EN state to trigger new power off/on sequence
3. check whether the power rail which requires these PG signals up first should keep off'	QS	Blocked by PG* does not block power on sequence issue. Please refer to https://nvbugs/3616373		Kent Wang & System QA		https://nvbugs/3616373		'Attempt power cycle multiple times, if that doesn''t work RMA the board.'	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_35	Failure resolution with a DC power cycle once the induced system failure during power-up is removed.	Capable through DFT/DFV		Block by  FPGA bug found in FPGA_34. Would give new ETA when the bug is fixed.	'1. generate several pulses on PG signals
2. override BASE_PWR_EN state to trigger now power off/on sequence in paralle with step#1
3. check whether all components PWR_GD/reset could still be correct state after pulses on PG signals have stopped.'	QS	Blocked by PG* does not block power on sequence issue. Please refer to https://nvbugs/3616373		Kent Wang & System QA				if the failure is removed and we are still hitting issue. It is likely a FPGA bug. Provide FPGA team with the register dump and FPGA team would need to provide fix. 	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_36	BMC PCIE error report for Invalid TLP 	Capable through config space override with i2ctools/devmem		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Disable FPGA PCIE memory space through FPGA PCI config space command register in BMC console
2. Send TLP memory request from BMC to FPGA
3. Check AER table and SMBPBI request to confirm invalid TLP count has increased'	QS	PASS with FPGA FW v1.42		Kent Wang & System QA		https://nvbugs/3584738		Follow PCIE base spec for recovery, Vishal please comment	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_37	HMC PCIE error report for Invalid TLP 	Need BMC team to confirm whether it supports devmem from HMC. Capable through config space override with i2ctools/devmem		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. Disable FPGA PCIE memory space through FPGA PCI config space command register in BMC console
2. Send TLP memory request from HMC to FPGA
3. Check AER table and SMBPBI request to confirm invalid TLP count has increased'	QS	PASS with FPGA FW v1.42		Kent Wang & System QA		https://nvbugs/3585195		Follow PCIE base spec for recovery, Vishal please comment	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_38	SPI error injection during Glacier FW update in parallel	Capable through DFT/DFV with PLDM update tools		Move to 2022/05/20 due to Scout FPGA validation test requested by Peter/TEST system not available(Original schedule 2022/04/29) 	'1. generate pulse on specific Glacer SPI
2. send Glacier FW update request from BMC or HMC in parallel with step#1
3. this specific Glacier FW update might fail, but other Glacier FW update should not be affected by this SPI signals pulse
4. After pulses stop, Glacier FW update should work for all Glaciers'	QS	PASS with FPGA FW v1.60		Kent Wang & System QA		https://nvbugs/3651422		When this happens, we would hit PLDM firmware update failure. Users should just try again to see if the glitch is intermittent. If the PLDM firmware update continously fails. The SPI interface has problems. We probably want to RMA the board here. 	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_39	SPI error injection during FPGA FW update	Capable through DFT/DFV with PLDM update tools		Move to 2022/05/20 due to Scout FPGA validation test requested by Peter/TEST system not available(Original schedule 2022/04/29)	'1. generate pulse on specific FPGA Glacer SPI
2. send FPGA FW update request from BMC or HMC in parallel with step#1
3. FPGA FW update might fail 
4. After pulses stop, send FPGA FW update request again and FPGA FW update should work again.'	QS	PASS with FPGA FW v1.60		Kent Wang & System QA				When this happens, we would hit PLDM firmware update failure. Users should just try again to see if the glitch is intermittent. If the PLDM firmware update continously fails. The SPI interface has problems. We probably want to RMA the board here. 	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_40	SMBPBI access to GPU/LS devices where devices return NACKs.	Capable through DFT/DFV with i2ctools		Move to 2022/05/13 due to Scout FPGA validation test requested by Peter(Original schedule 2022/04/29)	'1. force GPU/LS PWR_GD to low through DFT/DFV
2. send SMBPBI request to related GPU/LS10, it would get NACK. I2C1 or I2C2 alert would be triggered and SMBPBI could indicate it is NACK error.
3. SMBPBI for other devices should not be affected.
4. Change GPU/LS PWR_GD back to normal, clear the alert and need to reboot the system for another test.'	QS	Fail with error status report		Rhys Hou & System QA		https://nvbugs/3646214		'Try the same command again to see if NACK failure persists. If so, the i2c interface is not functional or GPU device SMBPBI server is not functional.   Users can attempt reset the GPU or DC cycle the board to try to recover. If these method doesn''t work, Vishal/Heniz to see if we need RMA on this.
'	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_41	Invalid PCIE TLPs noncompliant to SMBPBI proxy specifications.	Need experiment		Move to 2022/05/20 due to Scout FPGA validation test requested by Peter(Original schedule 2022/05/06)	'1. use devmem to read bar0 space which is outside FPGA/GPU/LS10 proxy register range and check proxy status register/AER table to see whether any error is reported.
Need to cover different non-FATAL proxy errors
2. use devmem to read/write bar0 space for more than 4 bytes and check whether proxy status register/AER table to see whether any error is reported.(becuase BMC could not support move than 4 bytes read) 
2. Need to add ERR_PAYLOAD/ERR_DIRECT_CMD, ETA: 5/27'	QS	CASE 1 PASS with FPGA FW v1.43		Kent Wang & System QA		https://nvbugs/3609185		send in another with the compliant SMBPBI proxy commands	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_42	Interleave SMBPBI commands to different devices over PCIE.	Capable through devmem tool		Fri Apr 15 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	1. use AIO tool Multi-client function to send SMBPBI request through devmem to all GPU/NVSW and FPGA ,see whether it could work.	QS	'PASS with FPGA FW v1.5.176
FAIL with FPGA FW v1.43'		Kent Wang & System QA		https://nvbugs/3605890		'if it repeated doesn''t work, it is an FPGA bug. Live Debug session would be ideal to quickly triage this issue, and FPGA team would provide fix. '	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_43	HMC continuously sends SMBPBI requests even though it already saw the access is given to BMC.	Capable through i2ctools		Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. use SMBPBI to request SMBPBI fencing for BMC
2. send SMBPBI request from HMC and it would get NACK.'	QS	PASS with FPGA FW v1.43		Kent Wang & System QA		https://nvbugs/3588377		HMC should not be able to do such thing, if it is able to do so, it is an FPGA bug, report to FPGA team immedately, and we will fix.	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_44	Alert caused by HERM/HMC/CAR_COME PRSNT state run time change	Capable through DFT/DFV		Move to 2022/05/25 due to Scout FPGA validation test requested by Peter(Original schedule 2022/04/29)	'1. Use DFT/DFV logic to toggle HERM/HMC/CAR_COME PRSNT pins
2. I2C2 ALERT pin could assert to notify BMC and SMBPBI could return correct interrupt source
3. related HERM/HMC/CAR_COME reset would assert'	QS	PASS with v1.56		Rhys Hou & System QA					TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
FPGA	FPGA_45	I2C access to GPU devices where devices return NACKs.	Capable through DFT/DFV with i2ctools		Wed May 25 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	'1. force GPU PWR_GD to low through DFT/DFV
2. send direct I2C request to related GPU, it would get NACK. I2C1 alert would be triggered and SMBPBI could indicate it is NACK error.
3. I2C for other devices should not be affected.
4. Change GPU PWR_GD back to normal, clear the alert and need to reboot the system for another test.'	QS	Fail with error status report		Rhys Hou & System QA		https://nvbugs/3646214		'Try the same command again to see if NACK failure persists. If so, the i2c interface is not functional or GPU device SMBPBI server is not functional.   Users can attempt reset the GPU or DC cycle the board to try to recover. If these method doesn''t work, Vishal/Heniz to see if we need RMA on this.
'	TBD	'4/27 Note:
New item and need further evaluation. Check with Vishal.'									{FPGAId} Register Table
Retimer	Retimer_1	Retimer[0-7] PCIe link goes down	'Retimer: Astera Labs retimers have error injection registers we can access over SMBus. (errinj_txdata) They don''t provide a tool for utilizing this register, it''s generally not a feature exposed to customers. Disclosed to NV as part of some FPGA work. Tool / capability to use it needs developed.'	Joseph Obedowski US		A PCIe link was established and then went away for some reason (lost power, internal failure).	QS			System QA		3586773		No immediate recovery required. If this event occurs multiple times in a short period, need to check other PCIe error status for further diagnostics.	'1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeRetimerId} PCIe", "LTSSM Link Down"]

and AdditionalData:
{PCIeRetimerId} PCIe LTSSM state


2. Update Resolution of redfish event log to:
No immediate recovery required. If this event occurs multiple times in a short period, need to check other PCIe error status for further diagnostics.'	'HMC can observe that a link is gone down, however the PCIe root complex will see the failure first and host system RAS handling will manage the error.

4/28 Note:
PCIe AER status notification has link down error.

No recovery for AER notification'			/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeRetimerId} PCIe", "LTSSM Link Down"]	{PCIeRetimerId} PCIe LTSSM state
Retimer	Retimer_2	Retimer[0-7] PCIe link never up	'Would suggest a custom Vulcan FPGA image that doesn''t release the reseets for the Retimers.  Alternatively I believe I heard Leon mention a register we can write and reboot the platform which will hold retimers (or maybe other devices) in reset'	Joseph Obedowski US		Retimer is unable to establish an initial link to downstream GPU. This results in the root complex never being able to enumerate a device. No PCIe error reporting is expected	QS			System QA		3586773		Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeRetimerId} PCIe", "Link Down"]

and AdditionalData:
{PCIeRetimerId} PCIe link status


Update Resolution of redfish event log to:
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'4/28 Note:
Check if Retimer in reset from FPGA. Do not see clock coming in. Otherwise, check GPIO_0 firmware is loaded properly.
Kun - healthrollup for 1. in reset or 2. firmware loaded properly

Ask Leon - 
1. Why holding in reset? clock, power, themal..(need debug) available in FPGA register dump? 
(and what condition will hold other devices in reset)
> we provide information for clock detect, clk enable, clk buf configuration power 

2. reprogram fw

5/5
"1. Create a redfish event log 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
[""{PCIeRetimerId} PCIe"", "Link down"]

AdditionalDataURL: clock detect, clk enable, clk buf configuration power.

2. Update Resolution of redfish event log to:
No immediate recovery required. If this event occurs multiple times in a short period, need to check other PCIe error status for further diagnostics."'	/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeRetimerId} PCIe", "Link Down"]	{PCIeRetimerId} PCIe link status
Retimer	Retimer_3	Retimer[0-7] I2C EEPROM Error	'Flash a bad firmware image.  Would need to be manual with a Comet dongle for recovery.
/System QA to modify bytes in a good image and write that to eeprom using Redfish FW update'	Jimmy Huang TW		Retimer is unable to fully read its EEPROM via I2C during its boot-up process. This will result in the retimer not configuring itself properly and no PCIe link being established.	QS			System QA			FPGA does not currently take action based on this signal	Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeRetimerId} Firmware", "EEPROM Error"]

and AdditionalData:



Update Resolution of redfish event log to:
Power cycle the BaseBoard. If the problem persists, isolate the server for RMA evaluation.'	'[AO] FPGA has HW signals that indicate Rerimers failed to load FW from their EEPROM. HMC can then get access to this information via I2C/PCIe.

4/28 Note:
HMC I2C2 or I2C4 to Reimer EEPROM
Ask Leon - is there a way to reset I2C through FPGA?
> no, we don''t allow such thing. We guarantee i2c will not hang due to fpga. We have a hang-free architecture. 

BMC/HMC I2C Direct Acdess (Mux) to EEPROM
(another case - Indirect Access - Retimer to EEPROM)'	/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeRetimerId} Firmware", "EEPROM Error"]	
Retimer	Retimer_4	Retimer[0-3, 4-7] Over Temp	'1.Run without a heatsink?
2. Use FPGA DFT to test this'	Leon/Amanda	Fri Apr 01 2022 00:00:00 GMT-0700 (Pacific Daylight Time)	Temperature sensor connected to retimer goes over the temperature threshold and issues alert	QS			System QA		3587955	FPGA asserts MIDP_OVERT	Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. 	'1. Change HealthRollup for following URIs 
 /redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorThresholdExceeded

and MessageArgs: 
["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]

and AdditionalData:
{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters


Update Resolution of redfish event log to:
Power off the BaseBoard within 1 second, and the Retimer will be held in reset. Check thermal environmental to ensure the Retimer operates under UpperFatal threshold and power cycle the BaseBoard to recover. '		/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	/redfish/v1/Chassis/{BaseboardId}/Sensors/{RetimerTempId}	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has exceeded error threshold of value %2.	ResourceEvent.1.0.ResourceErrorThresholdExceeded	ResourceEvent	["{PCIeRetimerId} Temperature", "{UpperFatal Threshold}"]	'{PCIeRetimerId} Temperature
{PCIeRetimerId} Thermal Parameters'
Retimer	Retimer_5	Incorrect link width	'1.We could potentially program a very bad initial EQ preset on particular lanes, otherwise GPU Dfx feature?
2. Change the link width on the upstream port'	Joseph Obedowski US		Link through the retimer is not able to negotiate correct settings	QS			System QA		3586773	none known	Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeRetimerId} PCIe", "Abnormal Width Change"]

and AdditionalData:
{PCIeRetimerId} PCIe link width


Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.'		/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeRetimerId} PCIe", "Abnormal Width Change"]	{PCIeRetimerId} PCIe link width
Retimer	Retimer_6	Incorrect link speed	I expect we could just set the downstream port above the retimers to link at a lower speed.  That should show it as being in the degraded state.	Jimmy Huang TW		Link through the retimer is not able to negotiate correct settings	QS			System QA		3586773	none known	Reset the link. If problem persists, isolate the server for RMA evaluation.	'1. Change HealthRollup for following URIs 
 /redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId} 

to Severity: Critical, and update Conditions.

2. Create a Redfish event log. Accessible through: 
/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}

with MessageId: 
ResourceEvent.1.0.ResourceErrorsDetected

and MessageArgs: 
["{PCIeRetimerId} PCIe", "Abnormal Speed Change"]

and AdditionalData:
{PCIeRetimerId} PCIe link speed
{PCIeRetimerId} PCIe requested link speed


Update Resolution of redfish event log to:
Reset the link. If problem persists, isolate the server for RMA evaluation.'		/redfish/v1/Fabrics/{FabricId}/Switches/{PCIeRetimerId}	n/a (no dependent condition)	/redfish/v1/Systems/{ComputerSystemId}LogServices/{LogServiceId}/Entries/{EntryId}	Critical	The resource property %1 has detected errors of type %2.	ResourceEvent.1.0.ResourceErrorsDetected	ResourceEvent	["{PCIeRetimerId} PCIe", "Abnormal Speed Change"]	'{PCIeRetimerId} PCIe link speed
{PCIeRetimerId} PCIe requested link speed'
Retimer	Retimer_7	FW Update with WP engaged - HMC	 Can be done from BMC				QS							TBD	TBD										
